{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thử nghiệm nâng cao: Ensemble, Multivariate & Hybrid Models\n",
    "\n",
    "## Phạm vi thử nghiệm\n",
    "1. **Ensemble đơn biến**: Kết hợp Linear + DLinear + NLinear\n",
    "2. **Đa biến (Multivariate)**: Sử dụng OHLCV features\n",
    "3. **Hybrid DLinear + Transformer**: Decomposition + Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/FPT_train.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Date range: {df['time'].min()} → {df['time'].max()}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df['close_log'] = np.log(df['close'])\n",
    "df['open_log'] = np.log(df['open'])\n",
    "df['high_log'] = np.log(df['high'])\n",
    "df['low_log'] = np.log(df['low'])\n",
    "df['volume_log'] = np.log(df['volume'] + 1)\n",
    "df['hl_spread'] = (df['high'] - df['low']) / df['close']\n",
    "df['oc_spread'] = (df['close'] - df['open']) / df['open']\n",
    "df = df.ffill().bfill()\n",
    "\n",
    "# Split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "n_total = len(df)\n",
    "train_cutoff = int(n_total * train_ratio)\n",
    "\n",
    "print(f\"Train cutoff: {train_cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "# Univariate\n",
    "uni_scaler = StandardScaler()\n",
    "uni_scaler.fit(df['close_log'].values[:train_cutoff].reshape(-1, 1))\n",
    "df['close_scaled'] = uni_scaler.transform(df['close_log'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Multivariate - scale từng feature riêng\n",
    "multi_cols = ['open_log', 'high_log', 'low_log', 'close_log', 'volume_log', 'hl_spread', 'oc_spread']\n",
    "multi_scaler = StandardScaler()\n",
    "multi_scaler.fit(df[multi_cols].values[:train_cutoff])\n",
    "multi_scaled = multi_scaler.transform(df[multi_cols].values)\n",
    "\n",
    "print(f\"Univariate feature: close_scaled\")\n",
    "print(f\"Multivariate features: {len(multi_cols)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnivariateDataset(Dataset):\n",
    "    def __init__(self, series, seq_len, pred_len):\n",
    "        self.series = series.astype(np.float32)\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.length = max(0, len(self.series) - seq_len - pred_len + 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.series[idx: idx + self.seq_len]\n",
    "        y = self.series[idx + self.seq_len: idx + self.seq_len + self.pred_len]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "\n",
    "class MultivariateDataset(Dataset):\n",
    "    def __init__(self, features, target, seq_len, pred_len):\n",
    "        self.features = features.astype(np.float32)\n",
    "        self.target = target.astype(np.float32)\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.length = max(0, len(self.features) - seq_len - pred_len + 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx: idx + self.seq_len]\n",
    "        y = self.target[idx + self.seq_len: idx + self.seq_len + self.pred_len]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "seq_lengths = {'7d': 7, '30d': 30, '120d': 120, '480d': 480}\n",
    "pred_len = 100\n",
    "batch_size = 32\n",
    "num_epochs = 500\n",
    "patience = 80\n",
    "lr = 1e-3\n",
    "\n",
    "# Prepare data\n",
    "series_uni = df['close_scaled'].values\n",
    "# Cho multivariate, target là cột close_log đã scale (index 3)\n",
    "target_multi = multi_scaled[:, 3]  # close_log_scaled\n",
    "n_features = len(multi_cols)\n",
    "close_idx = 3\n",
    "\n",
    "# Create datasets\n",
    "uni_datasets = {}\n",
    "multi_datasets = {}\n",
    "\n",
    "for name, seq_len in seq_lengths.items():\n",
    "    uni_datasets[name] = UnivariateDataset(series_uni, seq_len, pred_len)\n",
    "    multi_datasets[name] = MultivariateDataset(multi_scaled, target_multi, seq_len, pred_len)\n",
    "    print(f\"{name}: uni={len(uni_datasets[name])}, multi={len(multi_datasets[name])} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(dataset):\n",
    "    total = len(dataset)\n",
    "    train_len = int(total * train_ratio)\n",
    "    val_len = int(total * val_ratio)\n",
    "    return {\n",
    "        'train': torch.utils.data.Subset(dataset, list(range(train_len))),\n",
    "        'val': torch.utils.data.Subset(dataset, list(range(train_len, train_len + val_len))),\n",
    "        'test': torch.utils.data.Subset(dataset, list(range(train_len + val_len, total)))\n",
    "    }\n",
    "\n",
    "def make_loader(subset, batch_size, shuffle=False):\n",
    "    if subset is None or len(subset) == 0:\n",
    "        return None\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=shuffle, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Models\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(seq_len, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class NLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(seq_len, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len)\n",
    "        last = x[:, -1:]\n",
    "        return self.fc(x - last) + last\n",
    "\n",
    "\n",
    "class DLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.kernel_size = max(3, seq_len // 4)\n",
    "        self.fc_trend = nn.Linear(seq_len, pred_len)\n",
    "        self.fc_seasonal = nn.Linear(seq_len, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len)\n",
    "        # Simple moving average decomposition\n",
    "        trend = x.unfold(-1, self.kernel_size, 1).mean(-1)  # (B, seq_len - kernel + 1)\n",
    "        # Pad trend back to seq_len\n",
    "        pad_left = (self.seq_len - trend.size(-1)) // 2\n",
    "        pad_right = self.seq_len - trend.size(-1) - pad_left\n",
    "        trend = F.pad(trend, (pad_left, pad_right), mode='replicate')\n",
    "        seasonal = x - trend\n",
    "        return self.fc_trend(trend) + self.fc_seasonal(seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Models\n",
    "class WeightedEnsemble(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(seq_len, pred_len)\n",
    "        self.dlinear = DLinear(seq_len, pred_len)\n",
    "        self.nlinear = NLinear(seq_len, pred_len)\n",
    "        self.weights = nn.Parameter(torch.ones(3) / 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        p1 = self.linear(x)\n",
    "        p2 = self.dlinear(x)\n",
    "        p3 = self.nlinear(x)\n",
    "        w = F.softmax(self.weights, dim=0)\n",
    "        return w[0] * p1 + w[1] * p2 + w[2] * p3\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return F.softmax(self.weights, dim=0).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class StackingEnsemble(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(seq_len, pred_len)\n",
    "        self.dlinear = DLinear(seq_len, pred_len)\n",
    "        self.nlinear = NLinear(seq_len, pred_len)\n",
    "        self.meta = nn.Sequential(\n",
    "            nn.Linear(pred_len * 3, pred_len * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(pred_len * 2, pred_len)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        p1 = self.linear(x)\n",
    "        p2 = self.dlinear(x)\n",
    "        p3 = self.nlinear(x)\n",
    "        combined = torch.cat([p1, p2, p3], dim=-1)\n",
    "        return self.meta(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate Models\n",
    "class MultiLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, n_features):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(seq_len * n_features, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, n_features)\n",
    "        B = x.size(0)\n",
    "        return self.fc(x.reshape(B, -1))\n",
    "\n",
    "\n",
    "class MultiNLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, n_features, close_idx=3):\n",
    "        super().__init__()\n",
    "        self.close_idx = close_idx\n",
    "        self.fc = nn.Linear(seq_len * n_features, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, n_features)\n",
    "        B = x.size(0)\n",
    "        last_close = x[:, -1, self.close_idx:self.close_idx+1]  # (B, 1)\n",
    "        return self.fc(x.reshape(B, -1)) + last_close\n",
    "\n",
    "\n",
    "class MultiDLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, n_features, close_idx=3):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.close_idx = close_idx\n",
    "        self.kernel_size = max(3, seq_len // 4)\n",
    "        self.fc_trend = nn.Linear(seq_len * n_features, pred_len)\n",
    "        self.fc_seasonal = nn.Linear(seq_len * n_features, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, n_features)\n",
    "        B = x.size(0)\n",
    "        # Decompose close feature\n",
    "        close_seq = x[:, :, self.close_idx]  # (B, seq_len)\n",
    "        trend = close_seq.unfold(-1, self.kernel_size, 1).mean(-1)\n",
    "        pad_left = (self.seq_len - trend.size(-1)) // 2\n",
    "        pad_right = self.seq_len - trend.size(-1) - pad_left\n",
    "        trend = F.pad(trend, (pad_left, pad_right), mode='replicate')\n",
    "        \n",
    "        # Reconstruct with trend/seasonal close\n",
    "        seasonal = close_seq - trend\n",
    "        x_trend = x.clone()\n",
    "        x_seasonal = x.clone()\n",
    "        x_trend[:, :, self.close_idx] = trend\n",
    "        x_seasonal[:, :, self.close_idx] = seasonal\n",
    "        \n",
    "        return self.fc_trend(x_trend.reshape(B, -1)) + self.fc_seasonal(x_seasonal.reshape(B, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid DLinear + Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model > 1:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:d_model//2])\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class HybridDLinearTransformer(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, d_model=32, nhead=2, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.kernel_size = max(3, seq_len // 4)\n",
    "        \n",
    "        # Trend branch\n",
    "        self.fc_trend = nn.Linear(seq_len, pred_len)\n",
    "        \n",
    "        # Seasonal branch with Transformer\n",
    "        self.input_proj = nn.Linear(1, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, seq_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=0.1, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.output_proj = nn.Linear(d_model * seq_len, pred_len)\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len)\n",
    "        B = x.size(0)\n",
    "        \n",
    "        # Decompose\n",
    "        trend = x.unfold(-1, self.kernel_size, 1).mean(-1)\n",
    "        pad_left = (self.seq_len - trend.size(-1)) // 2\n",
    "        pad_right = self.seq_len - trend.size(-1) - pad_left\n",
    "        trend = F.pad(trend, (pad_left, pad_right), mode='replicate')\n",
    "        seasonal = x - trend\n",
    "        \n",
    "        # Trend prediction\n",
    "        trend_pred = self.fc_trend(trend)\n",
    "        \n",
    "        # Seasonal with Transformer\n",
    "        seasonal_emb = self.input_proj(seasonal.unsqueeze(-1))  # (B, seq_len, d_model)\n",
    "        seasonal_emb = self.pos_enc(seasonal_emb)\n",
    "        seasonal_out = self.transformer(seasonal_emb)  # (B, seq_len, d_model)\n",
    "        seasonal_pred = self.output_proj(seasonal_out.reshape(B, -1))\n",
    "        \n",
    "        # Combine\n",
    "        w = torch.sigmoid(self.alpha)\n",
    "        return w * trend_pred + (1 - w) * seasonal_pred\n",
    "    \n",
    "    def get_alpha(self):\n",
    "        return torch.sigmoid(self.alpha).item()\n",
    "\n",
    "\n",
    "class HybridMulti(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, n_features, close_idx=3, d_model=32, nhead=2, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.close_idx = close_idx\n",
    "        self.kernel_size = max(3, seq_len // 4)\n",
    "        \n",
    "        # Trend branch\n",
    "        self.fc_trend = nn.Linear(seq_len * n_features, pred_len)\n",
    "        \n",
    "        # Transformer branch\n",
    "        self.input_proj = nn.Linear(n_features, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, seq_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=0.1, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.output_proj = nn.Linear(d_model * seq_len, pred_len)\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, n_features)\n",
    "        B = x.size(0)\n",
    "        \n",
    "        # Trend from close\n",
    "        close_seq = x[:, :, self.close_idx]\n",
    "        trend = close_seq.unfold(-1, self.kernel_size, 1).mean(-1)\n",
    "        pad_left = (self.seq_len - trend.size(-1)) // 2\n",
    "        pad_right = self.seq_len - trend.size(-1) - pad_left\n",
    "        trend = F.pad(trend, (pad_left, pad_right), mode='replicate')\n",
    "        \n",
    "        x_trend = x.clone()\n",
    "        x_trend[:, :, self.close_idx] = trend\n",
    "        trend_pred = self.fc_trend(x_trend.reshape(B, -1))\n",
    "        \n",
    "        # Transformer\n",
    "        x_emb = self.input_proj(x)\n",
    "        x_emb = self.pos_enc(x_emb)\n",
    "        x_out = self.transformer(x_emb)\n",
    "        trans_pred = self.output_proj(x_out.reshape(B, -1))\n",
    "        \n",
    "        w = torch.sigmoid(self.alpha)\n",
    "        return w * trend_pred + (1 - w) * trans_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=80):\n",
    "        self.patience = patience\n",
    "        self.best_val = float('inf')\n",
    "        self.wait = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, val_loss, model):\n",
    "        if val_loss < self.best_val - 1e-5:\n",
    "            self.best_val = val_loss\n",
    "            self.wait = 0\n",
    "            self.best_state = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            self.wait += 1\n",
    "        return self.wait >= self.patience\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, lr, patience, device):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=30)\n",
    "    stopper = EarlyStopping(patience)\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for bx, by in train_loader:\n",
    "            bx, by = bx.to(device), by.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(bx)\n",
    "            loss = criterion(pred, by)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for bx, by in val_loader:\n",
    "                bx, by = bx.to(device), by.to(device)\n",
    "                val_loss += criterion(model(bx), by).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        if stopper.step(val_loss, model):\n",
    "            break\n",
    "    \n",
    "    if stopper.best_state:\n",
    "        model.load_state_dict(stopper.best_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, loader, scaler, pred_len, device):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for bx, by in loader:\n",
    "            bx = bx.to(device)\n",
    "            preds.append(model(bx).cpu().numpy())\n",
    "            trues.append(by.numpy())\n",
    "    \n",
    "    preds = np.vstack(preds)\n",
    "    trues = np.vstack(trues)\n",
    "    \n",
    "    # Inverse\n",
    "    preds_log = scaler.inverse_transform(preds.reshape(-1, 1)).reshape(-1, pred_len)\n",
    "    trues_log = scaler.inverse_transform(trues.reshape(-1, 1)).reshape(-1, pred_len)\n",
    "    preds_price = np.exp(preds_log)\n",
    "    trues_price = np.exp(trues_log)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(trues_price.flatten(), preds_price.flatten()))\n",
    "    mae = mean_absolute_error(trues_price.flatten(), preds_price.flatten())\n",
    "    \n",
    "    return {'rmse': rmse, 'mae': mae}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for horizon, seq_len in seq_lengths.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"HORIZON: {horizon} (seq_len={seq_len})\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Prepare loaders\n",
    "    uni_splits = create_splits(uni_datasets[horizon])\n",
    "    uni_train = make_loader(uni_splits['train'], batch_size, shuffle=True)\n",
    "    uni_val = make_loader(uni_splits['val'], batch_size)\n",
    "    uni_test = make_loader(uni_splits['test'], batch_size)\n",
    "    \n",
    "    multi_splits = create_splits(multi_datasets[horizon])\n",
    "    multi_train = make_loader(multi_splits['train'], batch_size, shuffle=True)\n",
    "    multi_val = make_loader(multi_splits['val'], batch_size)\n",
    "    multi_test = make_loader(multi_splits['test'], batch_size)\n",
    "    \n",
    "    # --- BASELINE ---\n",
    "    print(\"\\n[Baseline] NLinear...\", end=' ')\n",
    "    model = NLinear(seq_len, pred_len)\n",
    "    model = train_model(model, uni_train, uni_val, num_epochs, lr, patience, device)\n",
    "    metrics = evaluate(model, uni_test, uni_scaler, pred_len, device)\n",
    "    print(f\"RMSE: {metrics['rmse']:.2f}\")\n",
    "    all_results.append({'Horizon': horizon, 'Type': 'Baseline', 'Model': 'NLinear', **metrics})\n",
    "    \n",
    "    # --- ENSEMBLE ---\n",
    "    print(\"\\n[Ensemble] WeightedEnsemble...\", end=' ')\n",
    "    model = WeightedEnsemble(seq_len, pred_len)\n",
    "    model = train_model(model, uni_train, uni_val, num_epochs, lr, patience, device)\n",
    "    metrics = evaluate(model, uni_test, uni_scaler, pred_len, device)\n",
    "    w = model.get_weights()\n",
    "    print(f\"RMSE: {metrics['rmse']:.2f} (w: L={w[0]:.2f}, D={w[1]:.2f}, N={w[2]:.2f})\")\n",
    "    all_results.append({'Horizon': horizon, 'Type': 'Ensemble', 'Model': 'WeightedEnsemble', **metrics})\n",
    "    \n",
    "    print(\"[Ensemble] StackingEnsemble...\", end=' ')\n",
    "    model = StackingEnsemble(seq_len, pred_len)\n",
    "    model = train_model(model, uni_train, uni_val, num_epochs, lr, patience, device)\n",
    "    metrics = evaluate(model, uni_test, uni_scaler, pred_len, device)\n",
    "    print(f\"RMSE: {metrics['rmse']:.2f}\")\n",
    "    all_results.append({'Horizon': horizon, 'Type': 'Ensemble', 'Model': 'StackingEnsemble', **metrics})\n",
    "    \n",
    "    # --- MULTIVARIATE ---\n",
    "    print(\"\\n[Multi] MultiLinear...\", end=' ')\n",
    "    model = MultiLinear(seq_len, pred_len, n_features)\n",
    "    model = train_model(model, multi_train, multi_val, num_epochs, lr, patience, device)\n",
    "    metrics = evaluate(model, multi_test, uni_scaler, pred_len, device)\n",
    "    print(f\"RMSE: {metrics['rmse']:.2f}\")\n",
    "    all_results.append({'Horizon': horizon, 'Type': 'Multivariate', 'Model': 'MultiLinear', **metrics})\n",
    "    \n",
    "    print(\"[Multi] MultiNLinear...\", end=' ')\n",
    "    model = MultiNLinear(seq_len, pred_len, n_features, close_idx)\n",
    "    model = train_model(model, multi_train, multi_val, num_epochs, lr, patience, device)\n",
    "    metrics = evaluate(model, multi_test, uni_scaler, pred_len, device)\n",
    "    print(f\"RMSE: {metrics['rmse']:.2f}\")\n",
    "    all_results.append({'Horizon': horizon, 'Type': 'Multivariate', 'Model': 'MultiNLinear', **metrics})\n",
    "    \n",
    "    print(\"[Multi] MultiDLinear...\", end=' ')\n",
    "    model = MultiDLinear(seq_len, pred_len, n_features, close_idx)\n",
    "    model = train_model(model, multi_train, multi_val, num_epochs, lr, patience, device)\n",
    "    metrics = evaluate(model, multi_test, uni_scaler, pred_len, device)\n",
    "    print(f\"RMSE: {metrics['rmse']:.2f}\")\n",
    "    all_results.append({'Horizon': horizon, 'Type': 'Multivariate', 'Model': 'MultiDLinear', **metrics})\n",
    "    \n",
    "    # --- HYBRID ---\n",
    "    print(\"\\n[Hybrid] DLinear+Transformer (Uni)...\", end=' ')\n",
    "    model = HybridDLinearTransformer(seq_len, pred_len, d_model=32, nhead=2, num_layers=1)\n",
    "    model = train_model(model, uni_train, uni_val, num_epochs, lr*0.5, patience, device)\n",
    "    metrics = evaluate(model, uni_test, uni_scaler, pred_len, device)\n",
    "    print(f\"RMSE: {metrics['rmse']:.2f} (alpha: {model.get_alpha():.2f})\")\n",
    "    all_results.append({'Horizon': horizon, 'Type': 'Hybrid', 'Model': 'Hybrid-Uni', **metrics})\n",
    "    \n",
    "    print(\"[Hybrid] DLinear+Transformer (Multi)...\", end=' ')\n",
    "    model = HybridMulti(seq_len, pred_len, n_features, close_idx, d_model=32, nhead=2, num_layers=1)\n",
    "    model = train_model(model, multi_train, multi_val, num_epochs, lr*0.5, patience, device)\n",
    "    metrics = evaluate(model, multi_test, uni_scaler, pred_len, device)\n",
    "    print(f\"RMSE: {metrics['rmse']:.2f}\")\n",
    "    all_results.append({'Horizon': horizon, 'Type': 'Hybrid', 'Model': 'Hybrid-Multi', **metrics})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL RESULTS (sorted by RMSE)\")\n",
    "print(\"=\"*60)\n",
    "display(results_df.sort_values('rmse').head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best per horizon\n",
    "print(\"\\nBest model per horizon:\")\n",
    "for h in seq_lengths.keys():\n",
    "    best = results_df[results_df['Horizon'] == h].sort_values('rmse').iloc[0]\n",
    "    print(f\"{h}: {best['Model']} ({best['Type']}) - RMSE: {best['rmse']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = {'Baseline': 'black', 'Ensemble': 'steelblue', 'Multivariate': 'coral', 'Hybrid': 'green'}\n",
    "\n",
    "for idx, h in enumerate(seq_lengths.keys()):\n",
    "    ax = axes[idx]\n",
    "    h_df = results_df[results_df['Horizon'] == h].sort_values('rmse')\n",
    "    bar_colors = [colors[t] for t in h_df['Type']]\n",
    "    \n",
    "    bars = ax.barh(range(len(h_df)), h_df['rmse'], color=bar_colors)\n",
    "    ax.set_yticks(range(len(h_df)))\n",
    "    ax.set_yticklabels(h_df['Model'], fontsize=9)\n",
    "    ax.set_xlabel('RMSE')\n",
    "    ax.set_title(f'{h} Input')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    for bar, val in zip(bars, h_df['rmse']):\n",
    "        ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, f'{val:.1f}', va='center', fontsize=8)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=c, label=l) for l, c in colors.items()]\n",
    "fig.legend(handles=legend_elements, loc='upper right')\n",
    "plt.suptitle('RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "os.makedirs('results', exist_ok=True)\n",
    "results_df.to_csv('results/advanced_experiments.csv', index=False)\n",
    "print(\"Saved to results/advanced_experiments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Submission (100 ngày tiếp theo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn best model từ kết quả\n",
    "best_row = results_df.sort_values('rmse').iloc[0]\n",
    "best_horizon = best_row['Horizon']\n",
    "best_model_name = best_row['Model']\n",
    "best_type = best_row['Type']\n",
    "best_seq_len = seq_lengths[best_horizon]\n",
    "\n",
    "print(f\"Best model: {best_model_name} ({best_type})\")\n",
    "print(f\"Horizon: {best_horizon} (seq_len={best_seq_len})\")\n",
    "print(f\"Test RMSE: {best_row['rmse']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_future(model, input_data, scaler, device):\n",
    "    \"\"\"Dự báo 100 ngày tiếp theo\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.from_numpy(input_data.astype(np.float32)).unsqueeze(0).to(device)\n",
    "        pred_scaled = model(x).squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # Inverse transform\n",
    "    pred_log = scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
    "    pred_price = np.exp(pred_log)\n",
    "    return pred_price\n",
    "\n",
    "\n",
    "def create_model(model_name, seq_len, pred_len, n_features=None, close_idx=None):\n",
    "    \"\"\"Factory function để tạo model\"\"\"\n",
    "    if model_name == 'NLinear':\n",
    "        return NLinear(seq_len, pred_len)\n",
    "    elif model_name == 'WeightedEnsemble':\n",
    "        return WeightedEnsemble(seq_len, pred_len)\n",
    "    elif model_name == 'StackingEnsemble':\n",
    "        return StackingEnsemble(seq_len, pred_len)\n",
    "    elif model_name == 'MultiLinear':\n",
    "        return MultiLinear(seq_len, pred_len, n_features)\n",
    "    elif model_name == 'MultiNLinear':\n",
    "        return MultiNLinear(seq_len, pred_len, n_features, close_idx)\n",
    "    elif model_name == 'MultiDLinear':\n",
    "        return MultiDLinear(seq_len, pred_len, n_features, close_idx)\n",
    "    elif model_name == 'Hybrid-Uni':\n",
    "        return HybridDLinearTransformer(seq_len, pred_len)\n",
    "    elif model_name == 'Hybrid-Multi':\n",
    "        return HybridMulti(seq_len, pred_len, n_features, close_idx)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain best model trên 90% data\n",
    "print(f\"\\nRetraining {best_model_name} on 90% data...\")\n",
    "\n",
    "is_multi = best_type in ['Multivariate'] or best_model_name == 'Hybrid-Multi'\n",
    "\n",
    "if is_multi:\n",
    "    dataset = multi_datasets[best_horizon]\n",
    "else:\n",
    "    dataset = uni_datasets[best_horizon]\n",
    "\n",
    "# 90% train, 10% val\n",
    "total = len(dataset)\n",
    "train_len = int(total * 0.9)\n",
    "train_subset = torch.utils.data.Subset(dataset, list(range(train_len)))\n",
    "val_subset = torch.utils.data.Subset(dataset, list(range(train_len, total)))\n",
    "\n",
    "train_loader = make_loader(train_subset, batch_size, shuffle=True)\n",
    "val_loader = make_loader(val_subset, batch_size)\n",
    "\n",
    "# Create and train model\n",
    "if is_multi:\n",
    "    model = create_model(best_model_name, best_seq_len, pred_len, n_features, close_idx)\n",
    "else:\n",
    "    model = create_model(best_model_name, best_seq_len, pred_len)\n",
    "\n",
    "model = train_model(model, train_loader, val_loader, num_epochs, lr, patience, device)\n",
    "print(\"Retraining done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecast\n",
    "print(f\"\\nGenerating 100-day forecast...\")\n",
    "\n",
    "if is_multi:\n",
    "    # Lấy seq_len cuối của multivariate data\n",
    "    input_data = multi_scaled[-best_seq_len:].copy()\n",
    "else:\n",
    "    # Lấy seq_len cuối của univariate data\n",
    "    input_data = series_uni[-best_seq_len:]\n",
    "\n",
    "future_prices = forecast_future(model, input_data, uni_scaler, device)\n",
    "\n",
    "print(f\"Forecast range: {future_prices.min():.2f} - {future_prices.max():.2f} VND\")\n",
    "print(f\"First 5 days: {future_prices[:5]}\")\n",
    "print(f\"Last 5 days: {future_prices[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "os.makedirs('submissions', exist_ok=True)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': np.arange(1, pred_len + 1),\n",
    "    'close': future_prices\n",
    "})\n",
    "\n",
    "# Save với tên model\n",
    "submission_path = f'submissions/submission_{best_model_name.lower().replace(\"-\", \"_\")}_{best_horizon}.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "print(f\"Rows (including header): {len(submission) + 1}\")\n",
    "print(\"\\nPreview:\")\n",
    "display(submission.head(10))\n",
    "display(submission.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast vs historical\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Historical (last 150 days)\n",
    "hist_days = 150\n",
    "hist_dates = df['time'].iloc[-hist_days:]\n",
    "hist_prices = df['close'].iloc[-hist_days:]\n",
    "\n",
    "# Future dates\n",
    "last_date = df['time'].iloc[-1]\n",
    "future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=pred_len, freq='B')\n",
    "\n",
    "ax.plot(hist_dates, hist_prices, 'b-', linewidth=2, label='Historical')\n",
    "ax.plot(future_dates, future_prices, 'r--', linewidth=2, label=f'Forecast ({best_model_name})')\n",
    "ax.axvline(last_date, color='gray', linestyle=':', alpha=0.7, label='Forecast start')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Close Price (VND)')\n",
    "ax.set_title(f'FPT Stock Price Forecast - {best_model_name} ({best_horizon})')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo submission cho tất cả models (optional)\n",
    "print(\"\\nGenerating submissions for all models...\")\n",
    "\n",
    "all_submissions = []\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    model_name = row['Model']\n",
    "    horizon = row['Horizon']\n",
    "    model_type = row['Type']\n",
    "    seq_len = seq_lengths[horizon]\n",
    "    \n",
    "    is_multi = model_type in ['Multivariate'] or model_name == 'Hybrid-Multi'\n",
    "    \n",
    "    # Get dataset\n",
    "    if is_multi:\n",
    "        dataset = multi_datasets[horizon]\n",
    "    else:\n",
    "        dataset = uni_datasets[horizon]\n",
    "    \n",
    "    # Train/val split\n",
    "    total = len(dataset)\n",
    "    train_len = int(total * 0.9)\n",
    "    train_subset = torch.utils.data.Subset(dataset, list(range(train_len)))\n",
    "    val_subset = torch.utils.data.Subset(dataset, list(range(train_len, total)))\n",
    "    train_loader = make_loader(train_subset, batch_size, shuffle=True)\n",
    "    val_loader = make_loader(val_subset, batch_size)\n",
    "    \n",
    "    # Create model\n",
    "    if is_multi:\n",
    "        model = create_model(model_name, seq_len, pred_len, n_features, close_idx)\n",
    "    else:\n",
    "        model = create_model(model_name, seq_len, pred_len)\n",
    "    \n",
    "    # Train\n",
    "    model = train_model(model, train_loader, val_loader, num_epochs, lr, patience, device)\n",
    "    \n",
    "    # Forecast\n",
    "    if is_multi:\n",
    "        input_data = multi_scaled[-seq_len:].copy()\n",
    "    else:\n",
    "        input_data = series_uni[-seq_len:]\n",
    "    \n",
    "    prices = forecast_future(model, input_data, uni_scaler, device)\n",
    "    \n",
    "    # Save\n",
    "    sub = pd.DataFrame({'id': np.arange(1, pred_len + 1), 'close': prices})\n",
    "    filename = f'submissions/submission_{model_name.lower().replace(\"-\", \"_\")}_{horizon}.csv'\n",
    "    sub.to_csv(filename, index=False)\n",
    "    \n",
    "    all_submissions.append({\n",
    "        'Model': model_name,\n",
    "        'Horizon': horizon,\n",
    "        'Type': model_type,\n",
    "        'RMSE': row['rmse'],\n",
    "        'File': filename\n",
    "    })\n",
    "    print(f\"  {model_name} ({horizon}): {filename}\")\n",
    "\n",
    "print(f\"\\nTotal submissions: {len(all_submissions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "sub_df = pd.DataFrame(all_submissions).sort_values('RMSE')\n",
    "print(\"\\nAll submissions (sorted by Test RMSE):\")\n",
    "display(sub_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
