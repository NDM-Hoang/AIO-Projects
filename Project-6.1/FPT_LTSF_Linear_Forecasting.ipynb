{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEwY_KcTfFjh"
   },
   "source": [
    "# Dự báo 100 ngày giá đóng cửa FPT bằng LTSF-Linear\n",
    "\n",
    "## Phạm vi quy trình\n",
    "- Làm sạch và khám phá dữ liệu trong `FPT_train.csv`\n",
    "- Tạo đặc trưng log-price, chuẩn hóa theo chuẩn thời gian để tránh leakage\n",
    "- Huấn luyện các mô hình Linear, DLinear, NLinear với các độ dài chuỗi 7/30/120/480 ngày\n",
    "- Dự báo 100 ngày tiếp theo, đối chiếu kết quả và xuất file submission (101 dòng gồm header `id,close`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJqbnhnvfFjj"
   },
   "source": [
    "## 1. Import thư viện và đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhuVQ05CfGvz",
    "outputId": "c15a8a8e-09e5-4d2f-c904-4ace825186bb"
   },
   "outputs": [],
   "source": [
    "# Placeholder for optional download helpers (không dùng trong notebook này)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2PVpEp6fFjk",
    "outputId": "7768a7ad-dfec-4c44-d777-5fe31a951691"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Sử dụng thiết bị: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "qtgDityYfFjl",
    "outputId": "a81a9638-5857-4fc2-dafa-85c950786b33"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('FPT_train.csv')\n",
    "print(f\"FPT dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['time'].min()} → {df['time'].max()}\")\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "print(\"\\nMẫu dữ liệu đầu tiên:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nKiểu dữ liệu:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nThống kê cơ bản:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmyNC3kyfFjl"
   },
   "source": [
    "## 2. Khám phá dữ liệu & đặc trưng log-price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "I1cul11RfFjl",
    "outputId": "3f1348f0-c0ed-47b4-dc1b-0cb0c0476ccc"
   },
   "outputs": [],
   "source": [
    "# Tạo thêm đặc trưng cơ bản\n",
    "df['daily_return'] = df['close'].pct_change()\n",
    "df['close_log'] = np.log(df['close'])\n",
    "print(\"Đã thêm cột daily_return & close_log\")\n",
    "\n",
    "missing_info = df.isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xử lý missing values và chuẩn hóa theo train split\n",
    "df['daily_return'] = df['daily_return'].fillna(0)\n",
    "df['close_log'] = df['close_log'].ffill()\n",
    "df['close_log'] = df['close_log'].bfill()\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "\n",
    "train_cutoff = int(len(df) * train_ratio)\n",
    "log_scaler = StandardScaler()\n",
    "log_scaler.fit(df['close_log'].values[:train_cutoff].reshape(-1, 1))\n",
    "df['close_log_scaled'] = log_scaler.transform(df['close_log'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"Fit scaler trên {train_cutoff} quan sát đầu tiên (70% thời gian đầu)\")\n",
    "print(df[['time', 'close', 'close_log', 'close_log_scaled']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "09Ndrm0PvOBb",
    "outputId": "dd0ee711-4b0c-4777-ec04-ad456ca12fbe"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('FPT Stock Data Analysis - After Feature Creation', fontsize=16, fontweight='bold')\n",
    "\n",
    "axes[0, 0].plot(df['time'], df['close'], linewidth=1.5, color='blue', alpha=0.8)\n",
    "axes[0, 0].set_title('FPT Close Price', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Price (VND)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[0, 1].plot(df['time'], df['close_log'], linewidth=1.5, color='green', alpha=0.8)\n",
    "axes[0, 1].set_title('Log-transformed Price', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Log Price')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "ret_ts = df[['time', 'daily_return']].dropna().copy()\n",
    "ret_ts['ret_ma20'] = ret_ts['daily_return'].rolling(20).mean()\n",
    "axes[1, 0].plot(ret_ts['time'], ret_ts['daily_return'], linewidth=1.2, alpha=0.85, label='Daily Return')\n",
    "axes[1, 0].plot(ret_ts['time'], ret_ts['ret_ma20'], linewidth=2.0, linestyle='--', alpha=0.95, label='20D Avg')\n",
    "axes[1, 0].axhline(0, color='black', linewidth=1, alpha=0.6)\n",
    "axes[1, 0].set_title('Daily Return (%)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Return')\n",
    "axes[1, 0].yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "axes[1, 0].xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "axes[1, 0].xaxis.set_major_formatter(mdates.ConciseDateFormatter(mdates.AutoDateLocator()))\n",
    "axes[1, 0].tick_params(axis='x', rotation=0)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend(fontsize=9)\n",
    "\n",
    "axes[1, 1].plot(df['time'], df['volume'], linewidth=1.2, color='purple', alpha=0.75)\n",
    "axes[1, 1].set_title('Trading Volume', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Volume')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwFZVwKVfFjn"
   },
   "source": [
    "## 3. Chuẩn bị dataset chuỗi thời gian cho dự báo 100 ngày"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9N-8m4PfFjn",
    "outputId": "24fda7cc-3298-4474-a43e-6db49de47742"
   },
   "outputs": [],
   "source": [
    "class SlidingWindowDataset(Dataset):\n",
    "    \"\"\"Dataset trượt cho dự báo univariate\"\"\"\n",
    "    def __init__(self, series, seq_len, pred_len):\n",
    "        self.series = series.astype(np.float32)\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.length = max(0, len(self.series) - self.seq_len - self.pred_len + 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.series[idx: idx + self.seq_len]\n",
    "        y = self.series[idx + self.seq_len: idx + self.seq_len + self.pred_len]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "seq_lengths = {'7d': 7, '30d': 30, '120d': 120, '480d': 480}\n",
    "pred_len = 100\n",
    "series_scaled = df['close_log_scaled'].values\n",
    "\n",
    "datasets = {}\n",
    "for name, seq_len in seq_lengths.items():\n",
    "    dataset = SlidingWindowDataset(series_scaled, seq_len, pred_len)\n",
    "    datasets[name] = dataset\n",
    "    print(f\"{name}: seq_len={seq_len}, samples={len(dataset)}\")\n",
    "print(f\"Pred horizon: {pred_len} ngày\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxcSO94SfFjn",
    "outputId": "cec48e16-eca5-446f-81cd-5294bc228e60"
   },
   "outputs": [],
   "source": [
    "def create_time_based_splits(dataset):\n",
    "    total_len = len(dataset)\n",
    "    train_len = int(total_len * train_ratio)\n",
    "    val_len = int(total_len * val_ratio)\n",
    "    test_len = total_len - train_len - val_len\n",
    "\n",
    "    train_idx = list(range(0, train_len))\n",
    "    val_idx = list(range(train_len, train_len + val_len))\n",
    "    test_idx = list(range(train_len + val_len, total_len))\n",
    "\n",
    "    return {\n",
    "        'train': torch.utils.data.Subset(dataset, train_idx),\n",
    "        'val': torch.utils.data.Subset(dataset, val_idx),\n",
    "        'test': torch.utils.data.Subset(dataset, test_idx)\n",
    "    }\n",
    "\n",
    "data_splits = {name: create_time_based_splits(ds) for name, ds in datasets.items()}\n",
    "\n",
    "for name, splits in data_splits.items():\n",
    "    sizes = {split: len(subset) for split, subset in splits.items()}\n",
    "    print(f\"{name} → train {sizes['train']}, val {sizes['val']}, test {sizes['test']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhTs10nnRTo4"
   },
   "source": [
    "# 4. Cài đặt mô hình LTSF-Linear cho dự báo 100 ngày"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "279lY66GfFjm"
   },
   "source": [
    "## 4.1 Định nghĩa Linear / DLinear / NLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTPGw5OPfFjm",
    "outputId": "c0e83bbd-5c03-4839-a648-01d25f02b586"
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(seq_len, pred_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class DLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len, moving_avg=25):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        # Adaptive moving_avg based on seq_len\n",
    "        if moving_avg is None:\n",
    "            moving_avg = max(3, seq_len // 4)  # 25% of input length\n",
    "        self.moving_avg = max(2, min(moving_avg, seq_len - 1))\n",
    "        self.linear_trend = nn.Linear(seq_len, pred_len)\n",
    "        self.linear_seasonal = nn.Linear(seq_len, pred_len)\n",
    "        self.register_buffer('avg_kernel', torch.ones(1, 1, self.moving_avg) / self.moving_avg)\n",
    "\n",
    "    def decompose(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        x_reshaped = x.unsqueeze(1)\n",
    "        padding = self.moving_avg // 2\n",
    "        x_padded = torch.nn.functional.pad(x_reshaped, (padding, padding), mode='replicate')\n",
    "        trend = torch.nn.functional.conv1d(x_padded, self.avg_kernel, padding=0).squeeze(1)\n",
    "        if trend.shape[1] != seq_len:\n",
    "            trend = torch.nn.functional.interpolate(trend.unsqueeze(1), size=seq_len, mode='linear', align_corners=False).squeeze(1)\n",
    "        seasonal = x - trend\n",
    "        return trend, seasonal\n",
    "\n",
    "    def forward(self, x):\n",
    "        trend, seasonal = self.decompose(x)\n",
    "        return self.linear_trend(trend) + self.linear_seasonal(seasonal)\n",
    "\n",
    "class NLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(seq_len, pred_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        last = x[:, -1:].detach()\n",
    "        normalized = x - last\n",
    "        return self.linear(normalized) + last\n",
    "\n",
    "model_factories = {\n",
    "    'Linear': Linear,\n",
    "    'DLinear': DLinear,\n",
    "    'NLinear': NLinear\n",
    "}\n",
    "print(\"Đã khởi tạo factory cho Linear/DLinear/NLinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoAz9nzjQCS4"
   },
   "source": [
    "## 5. Huấn luyện với early stopping (1000 epochs tối đa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNUKp2fsfFjn",
    "outputId": "bc59d3c7-8652-4acb-89b8-790fa4d3ffca"
   },
   "outputs": [],
   "source": [
    "def make_loader(subset, batch_size, shuffle=False):\n",
    "    if subset is None or len(subset) == 0:\n",
    "        return None\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "def evaluate_model(model, loader, scaler, pred_len, device='cpu'):\n",
    "    if loader is None or len(loader.dataset) == 0:\n",
    "        return {'mse': np.nan, 'mae': np.nan, 'rmse': np.nan, 'r2': np.nan,\n",
    "                'pred_sequences_log': np.array([]), 'actual_sequences_log': np.array([]),\n",
    "                'pred_sequences_price': np.array([]), 'actual_sequences_price': np.array([])}\n",
    "\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            preds.append(outputs.cpu().numpy())\n",
    "            trues.append(batch_y.cpu().numpy())\n",
    "\n",
    "    preds = np.vstack(preds)\n",
    "    trues = np.vstack(trues)\n",
    "\n",
    "    preds_log = scaler.inverse_transform(preds.reshape(-1, 1)).reshape(-1, pred_len)\n",
    "    trues_log = scaler.inverse_transform(trues.reshape(-1, 1)).reshape(-1, pred_len)\n",
    "    preds_price = np.exp(preds_log)\n",
    "    trues_price = np.exp(trues_log)\n",
    "\n",
    "    mse = mean_squared_error(trues_price.flatten(), preds_price.flatten())\n",
    "    mae = mean_absolute_error(trues_price.flatten(), preds_price.flatten())\n",
    "    rmse = np.sqrt(mse)\n",
    "    try:\n",
    "        r2 = r2_score(trues_price.flatten(), preds_price.flatten())\n",
    "    except ValueError:\n",
    "        r2 = np.nan\n",
    "\n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'pred_sequences_log': preds_log,\n",
    "        'actual_sequences_log': trues_log,\n",
    "        'pred_sequences_price': preds_price,\n",
    "        'actual_sequences_price': trues_price\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TU9TNbFifFjo"
   },
   "source": [
    "### 5.1 Early stopping & hàm train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBuI_xgcfFjo",
    "outputId": "2fb7920a-587b-4095-8f10-56b82b5e960c"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=120, min_delta=1e-5):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val = float('inf')\n",
    "        self.wait = 0\n",
    "        self.best_state = None\n",
    "\n",
    "    def step(self, val_loss, model):\n",
    "        if val_loss + self.min_delta < self.best_val:\n",
    "            self.best_val = val_loss\n",
    "            self.wait = 0\n",
    "            self.best_state = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            self.wait += 1\n",
    "        return self.wait >= self.patience\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, lr, patience, device='cpu'):\n",
    "    if train_loader is None or val_loader is None:\n",
    "        raise ValueError(\"Train/val loader không hợp lệ\")\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=30, min_lr=1e-6\n",
    "    )\n",
    "    history = {'train': [], 'val': []}\n",
    "    stopper = EarlyStopping(patience=patience)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_train = 0.0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_x)\n",
    "            loss = criterion(preds, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train += loss.item()\n",
    "\n",
    "        train_loss = running_train / max(1, len(train_loader))\n",
    "        history['train'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        running_val = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                preds = model(batch_x)\n",
    "                running_val += criterion(preds, batch_y).item()\n",
    "        val_loss = running_val / max(1, len(val_loader))\n",
    "        scheduler.step(val_loss)\n",
    "        history['val'].append(val_loss)\n",
    "\n",
    "        if stopper.step(val_loss, model):\n",
    "            print(f\"Early stopping tại epoch {epoch} (val loss: {val_loss:.6f})\")\n",
    "            break\n",
    "\n",
    "    if stopper.best_state is not None:\n",
    "        model.load_state_dict(stopper.best_state)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ADDou-zfFjo"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 1000\n",
    "patience = 120\n",
    "learning_rate = 1e-3\n",
    "\n",
    "results = {name: {} for name in model_factories.keys()}\n",
    "trained_models = {name: {} for name in model_factories.keys()}\n",
    "\n",
    "for horizon, splits in data_splits.items():\n",
    "    seq_len = seq_lengths[horizon]\n",
    "    print(f\"\\n=== Horizon {horizon} (seq_len={seq_len}) ===\")\n",
    "    train_loader = make_loader(splits['train'], batch_size)\n",
    "    val_loader = make_loader(splits['val'], batch_size)\n",
    "    test_loader = make_loader(splits['test'], batch_size)\n",
    "\n",
    "    for model_name, ModelClass in model_factories.items():\n",
    "        print(f\"Huấn luyện {model_name}...\", end=' ')\n",
    "        model = ModelClass(seq_len, pred_len)\n",
    "        trained_model, history = train_model(\n",
    "            model, train_loader, val_loader, num_epochs, learning_rate, patience, device\n",
    "        )\n",
    "        metrics = evaluate_model(trained_model, test_loader, log_scaler, pred_len, device)\n",
    "        history['epochs_ran'] = len(history['train'])\n",
    "        results[model_name][horizon] = {**metrics, 'history': history}\n",
    "        trained_models[model_name][horizon] = trained_model\n",
    "        print(f\"Done. Test RMSE: {metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_U-BgdeTfFjo",
    "outputId": "92f71973-66cd-482f-d4c0-3d714eb5da31"
   },
   "outputs": [],
   "source": [
    "performance_rows = []\n",
    "for model_name, horizons in results.items():\n",
    "    for horizon, metrics in horizons.items():\n",
    "        performance_rows.append({\n",
    "            'Model': model_name,\n",
    "            'Horizon': horizon,\n",
    "            'Seq_Len': seq_lengths[horizon],\n",
    "            'RMSE': metrics['rmse'],\n",
    "            'MAE': metrics['mae'],\n",
    "            'MSE': metrics['mse'],\n",
    "            'R2': metrics['r2'],\n",
    "            'Epochs': metrics['history']['epochs_ran']\n",
    "        })\n",
    "performance_df = pd.DataFrame(performance_rows).sort_values('RMSE').reset_index(drop=True)\n",
    "print(\"\\nBảng hiệu năng (sắp theo RMSE):\")\n",
    "display(performance_df)\n",
    "\n",
    "best_row = performance_df.iloc[0]\n",
    "best_model_name = best_row['Model']\n",
    "best_horizon = best_row['Horizon']\n",
    "print(f\"\\nBest combo: {best_model_name} với input {best_horizon} (seq_len={seq_lengths[best_horizon]})\")\n",
    "best_history = results[best_model_name][best_horizon]['history']\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(best_history['train'], label='Train loss')\n",
    "plt.plot(best_history['val'], label='Val loss')\n",
    "plt.title(f\"Loss curve - {best_model_name} ({best_horizon})\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE (scaled)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Huấn luyện lại và xuất dự báo cho toàn bộ mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Huấn luyện lại 90% dữ liệu và xuất dự báo cho mọi model-horizon...\")\n",
    "os.makedirs('submissions', exist_ok=True)\n",
    "\n",
    "def forecast_future(model, series_scaled, seq_len, scaler, device='cpu'):\n",
    "    model.eval()\n",
    "    last_seq = torch.from_numpy(series_scaled[-seq_len:].astype(np.float32)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred_scaled = model(last_seq).squeeze(0).cpu().numpy()\n",
    "    pred_log = scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
    "    return np.exp(pred_log)\n",
    "\n",
    "final_models = {name: {} for name in model_factories.keys()}\n",
    "forecast_exports = []\n",
    "\n",
    "for horizon, seq_len in seq_lengths.items():\n",
    "    dataset = datasets[horizon]\n",
    "    full_len = len(dataset)\n",
    "    if full_len < 2:\n",
    "        print(f\"Bỏ qua {horizon} vì không đủ mẫu ({full_len}).\")\n",
    "        continue\n",
    "\n",
    "    full_train_len = max(1, int(full_len * 0.85))\n",
    "    train_subset = torch.utils.data.Subset(dataset, list(range(0, full_train_len)))\n",
    "    val_subset = torch.utils.data.Subset(dataset, list(range(full_train_len, full_len)))\n",
    "    train_loader = make_loader(train_subset, batch_size, shuffle=True)\n",
    "    val_loader = make_loader(val_subset, batch_size, shuffle=False)\n",
    "\n",
    "    for model_name, ModelClass in model_factories.items():\n",
    "        print(f\"Retraining {model_name} - {horizon}...\", end=' ')\n",
    "        model = ModelClass(seq_len, pred_len)\n",
    "        retrained_model, retrain_history = train_model(\n",
    "            model, train_loader, val_loader, num_epochs, learning_rate, patience, device\n",
    "        )\n",
    "        retrain_history['epochs_ran'] = len(retrain_history['train'])\n",
    "        final_models[model_name][horizon] = retrained_model\n",
    "\n",
    "        future_prices = forecast_future(retrained_model, series_scaled, seq_len, log_scaler, device)\n",
    "        forecast_df = pd.DataFrame({'id': np.arange(1, pred_len + 1), 'close': future_prices})\n",
    "        filename = f\"submission_{model_name.lower()}_{horizon}_100d.csv\"\n",
    "        filepath = os.path.join('submissions', filename)\n",
    "        forecast_df.to_csv(filepath, index=False)\n",
    "        forecast_exports.append({\n",
    "            'Model': model_name,\n",
    "            'Horizon': horizon,\n",
    "            'Seq_Len': seq_len,\n",
    "            'ForecastFile': filepath,\n",
    "            'RMSE_test': results[model_name][horizon]['rmse'],\n",
    "            'Retrain_epochs': retrain_history['epochs_ran']\n",
    "        })\n",
    "        print(f\"xong ({filepath})\")\n",
    "\n",
    "forecast_export_df = pd.DataFrame(forecast_exports).sort_values(['Model', 'Horizon']).reset_index(drop=True)\n",
    "print(\"\\nDanh sách file dự báo đã xuất:\")\n",
    "display(forecast_export_df)\n",
    "\n",
    "best_forecast_path = forecast_export_df[\n",
    "    (forecast_export_df['Model'] == best_model_name) &\n",
    "    (forecast_export_df['Horizon'] == best_horizon)\n",
    "]['ForecastFile'].iloc[0]\n",
    "best_forecast_df = pd.read_csv(best_forecast_path)\n",
    "future_prices = best_forecast_df['close'].values\n",
    "submission_path = best_forecast_path\n",
    "print(f\"\\nFile submission tương ứng combo tốt nhất: {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_psx_4IfFjo"
   },
   "source": [
    "## 7. Đối chiếu dự báo vs thực tế trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8Zp71_uafFjp",
    "outputId": "d672ec45-fe35-4baf-bb7f-fb01542545b9"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, horizon in enumerate(horizon_list):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for model_name in ['Linear', 'DLinear', 'NLinear']:\n",
    "        if horizon not in results.get(model_name, {}):\n",
    "            continue\n",
    "        metrics = results[model_name][horizon]\n",
    "        if metrics['pred_sequences_price'].size == 0:\n",
    "            continue\n",
    "        \n",
    "        # Tính MAE theo từng ngày forecast\n",
    "        errors = np.abs(metrics['pred_sequences_price'] - metrics['actual_sequences_price'])\n",
    "        mean_error_per_day = errors.mean(axis=0)  # Average over all test samples\n",
    "        \n",
    "        ax.plot(range(1, pred_len+1), mean_error_per_day, \n",
    "                label=f\"{model_name} (RMSE={metrics['rmse']:.1f})\")\n",
    "    \n",
    "    ax.set_title(f\"{horizon} Input - MAE theo ngày dự báo\")\n",
    "    ax.set_xlabel('Forecast day')\n",
    "    ax.set_ylabel('Mean Absolute Error (VND)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dự báo 100 ngày tiếp theo & xuất submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sử dụng combo tốt nhất: {best_model_name} với {best_horizon} (seq_len={seq_lengths[best_horizon]})\")\n",
    "print(f\"File submission được chọn: {submission_path}\")\n",
    "\n",
    "forecast_df = best_forecast_df.copy()\n",
    "display(forecast_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_window = 150\n",
    "history_data = df.tail(history_window)\n",
    "future_start = history_data['time'].iloc[-1] + pd.Timedelta(days=1)\n",
    "future_dates = pd.date_range(future_start, periods=pred_len, freq='B')  # Business days\n",
    "\n",
    "plot_models = list(model_factories.keys())\n",
    "horizon_list = list(seq_lengths.keys())\n",
    "fig_cols = 2\n",
    "fig_rows = int(np.ceil(len(horizon_list) / fig_cols))\n",
    "\n",
    "for model_name in plot_models:\n",
    "    print(f\"\\n=== {model_name} Forecasts ===\")\n",
    "    fig, axes = plt.subplots(fig_rows, fig_cols, figsize=(16, 4 * fig_rows), sharex=False)\n",
    "    axes = np.atleast_1d(axes).flatten()\n",
    "    for ax in axes[len(horizon_list):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    for idx, horizon in enumerate(horizon_list):\n",
    "        ax = axes[idx]\n",
    "        ax.plot(history_data['time'], history_data['close'], label='Actual (last 150d)', linewidth=2, color='black')\n",
    "        ax.axvline(history_data['time'].iloc[-1], color='gray', linestyle=':', label='Forecast start')\n",
    "\n",
    "        mask = (forecast_export_df['Model'] == model_name) & (forecast_export_df['Horizon'] == horizon)\n",
    "        if mask.sum() == 0:\n",
    "            ax.text(0.5, 0.5, \"Không có dự báo\", ha='center', va='center')\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "\n",
    "        forecast_path = forecast_export_df.loc[mask, 'ForecastFile'].iloc[0]\n",
    "        model_forecast_df = pd.read_csv(forecast_path)\n",
    "        preds = model_forecast_df['close'].values\n",
    "        ax.plot(future_dates[:len(preds)], preds[:len(future_dates)], linestyle='--', linewidth=1.6, label=f\"{model_name} forecast\")\n",
    "\n",
    "        ax.set_title(f\"{horizon} Input → 100d Forecast ({model_name})\")\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Close price (VND)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_check = pd.read_csv(submission_path)\n",
    "print(f\"Submission rows (bao gồm header): {len(submission_check) + 1}\")\n",
    "print(submission_check.head())\n",
    "print(submission_check.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_export_path = 'submissions/fpt_ltsf_performance.csv'\n",
    "performance_df.to_csv(performance_export_path, index=False)\n",
    "\n",
    "comparison_export_path = 'submissions/fpt_forecast_manifest.csv'\n",
    "forecast_export_df.to_csv(comparison_export_path, index=False)\n",
    "\n",
    "print(f\"Đã lưu bảng hiệu năng tại {performance_export_path}\")\n",
    "print(f\"Đã lưu manifest forecast tại {comparison_export_path}\")\n",
    "print(f\"Combo tốt nhất: {best_model_name} với {best_horizon}, file submission: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
