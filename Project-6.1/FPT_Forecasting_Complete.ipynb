{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPT Stock Price Forecasting - Complete Pipeline\n",
    "\n",
    "## Objective:\n",
    "- Predict FPT closing prices for the next 100 days\n",
    "- Use Linear, DLinear, NLinear models with univariate time series\n",
    "- Input window sizes: 7d, 30d, 120d, 480d\n",
    "- Train with Early Stopping (max 1000 epochs)\n",
    "- Save predictions to submission file (101 lines: header + 100 predictions)\n",
    "- Plot and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FPT training data\n",
    "df = pd.read_csv('FPT_train.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['time'].min()} to {df['time'].max()}\")\n",
    "print(f\"Total data points: {len(df)} rows\")\n",
    "print(f\"\\nLast date in training data: {df['time'].iloc[-1]}\")\n",
    "print(f\"Next 100 days will start from: {df['time'].iloc[-1] + timedelta(days=1)}\")\n",
    "\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize FPT stock price\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('FPT Stock Data Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Close price over time\n",
    "axes[0, 0].plot(df['time'], df['close'], linewidth=1.5, color='blue', alpha=0.8)\n",
    "axes[0, 0].set_title('FPT Closing Price Over Time')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Price (VND)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Distribution\n",
    "axes[0, 1].hist(df['close'], bins=50, color='green', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Price Distribution')\n",
    "axes[0, 1].set_xlabel('Price (VND)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Daily returns\n",
    "df['daily_return'] = df['close'].pct_change()\n",
    "axes[1, 0].plot(df['time'], df['daily_return'], linewidth=1, alpha=0.7, color='red')\n",
    "axes[1, 0].axhline(0, color='black', linewidth=1, alpha=0.5)\n",
    "axes[1, 0].set_title('Daily Returns')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Return')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Volume\n",
    "axes[1, 1].plot(df['time'], df['volume'], linewidth=1, color='purple', alpha=0.7)\n",
    "axes[1, 1].set_title('Trading Volume')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Volume')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Time Series Dataset\n",
    "class UnivariateTimeSeriesDataset(Dataset):\n",
    "    \"\"\"Dataset for univariate time series forecasting\"\"\"\n",
    "    def __init__(self, data, seq_len, pred_len, target_col='close'):\n",
    "        self.data = data.dropna().reset_index(drop=True)\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.target_col = target_col\n",
    "        self.series = self.data[target_col].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.series) - self.seq_len - self.pred_len + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.series[idx:idx+self.seq_len].copy()\n",
    "        y = self.series[idx+self.seq_len:idx+self.seq_len+self.pred_len].copy()\n",
    "        return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "\n",
    "# Create datasets for different window sizes\n",
    "seq_lengths = [7, 30, 120, 480]\n",
    "pred_len = 1  # Predict 1 step for validation, but we'll use for multi-step later\n",
    "\n",
    "datasets = {}\n",
    "for seq_len in seq_lengths:\n",
    "    dataset = UnivariateTimeSeriesDataset(\n",
    "        data=df, \n",
    "        seq_len=seq_len, \n",
    "        pred_len=pred_len,\n",
    "        target_col='close'\n",
    "    )\n",
    "    datasets[f'{seq_len}d'] = dataset\n",
    "    print(f\"Dataset {seq_len}d: {len(dataset)} samples\")\n",
    "\n",
    "print(f\"\\nCreated {len(datasets)} datasets for window sizes: {seq_lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split - Preserving temporal order (no shuffling)\n",
    "# Given small dataset (1149 rows), use 80/20 split\n",
    "def create_time_based_splits(dataset, train_ratio=0.8):\n",
    "    \"\"\"Create time-based train/test splits\"\"\"\n",
    "    total_len = len(dataset)\n",
    "    train_len = int(total_len * train_ratio)\n",
    "    \n",
    "    train_indices = list(range(0, train_len))\n",
    "    test_indices = list(range(train_len, total_len))\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# Create splits\n",
    "data_splits = {}\n",
    "print(\"Creating train/test splits (80/20):\")\n",
    "print(\"Note: Temporal order preserved to avoid data leakage\\n\")\n",
    "\n",
    "for seq_name, dataset in datasets.items():\n",
    "    train, test = create_time_based_splits(dataset, train_ratio=0.8)\n",
    "    data_splits[seq_name] = {'train': train, 'test': test}\n",
    "    print(f\"{seq_name}: Train={len(train)}, Test={len(test)}\")\n",
    "\n",
    "print(\"\\n✓ Data splits created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "class Linear(nn.Module):\n",
    "    \"\"\"Simple Linear model for time series forecasting\"\"\"\n",
    "    def __init__(self, seq_len, pred_len=1):\n",
    "        super(Linear, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.linear = nn.Linear(seq_len, pred_len)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# DLinear Model\n",
    "class DLinear(nn.Module):\n",
    "    \"\"\"Decomposition Linear - handles trend and seasonality\"\"\"\n",
    "    def __init__(self, seq_len, pred_len=1, moving_avg=5):\n",
    "        super(DLinear, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.moving_avg = min(moving_avg, seq_len - 1)\n",
    "        \n",
    "        self.linear_trend = nn.Linear(seq_len, pred_len)\n",
    "        self.linear_seasonal = nn.Linear(seq_len, pred_len)\n",
    "        \n",
    "        # Moving average kernel\n",
    "        self.register_buffer('avg_kernel', torch.ones(1, 1, self.moving_avg) / self.moving_avg)\n",
    "    \n",
    "    def decompose(self, x):\n",
    "        \"\"\"Decompose into trend and seasonal components\"\"\"\n",
    "        batch_size, seq_len = x.shape\n",
    "        x_reshaped = x.unsqueeze(1)\n",
    "        \n",
    "        padding = self.moving_avg // 2\n",
    "        x_padded = torch.nn.functional.pad(x_reshaped, (padding, padding), mode='replicate')\n",
    "        trend = torch.nn.functional.conv1d(x_padded, self.avg_kernel, padding=0)\n",
    "        trend = trend.squeeze(1)\n",
    "        \n",
    "        if trend.shape[1] != seq_len:\n",
    "            trend = torch.nn.functional.interpolate(\n",
    "                trend.unsqueeze(1), size=seq_len, mode='linear', align_corners=False\n",
    "            ).squeeze(1)\n",
    "        \n",
    "        seasonal = x - trend\n",
    "        return trend, seasonal\n",
    "    \n",
    "    def forward(self, x):\n",
    "        trend, seasonal = self.decompose(x)\n",
    "        trend_pred = self.linear_trend(trend)\n",
    "        seasonal_pred = self.linear_seasonal(seasonal)\n",
    "        return trend_pred + seasonal_pred\n",
    "\n",
    "# NLinear Model\n",
    "class NLinear(nn.Module):\n",
    "    \"\"\"Normalized Linear - handles distribution shift\"\"\"\n",
    "    def __init__(self, seq_len, pred_len=1):\n",
    "        super(NLinear, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.linear = nn.Linear(seq_len, pred_len)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Normalize by last value\n",
    "        last_value = x[:, -1:]\n",
    "        x_normalized = x - last_value\n",
    "        pred_normalized = self.linear(x_normalized)\n",
    "        pred = pred_normalized + last_value\n",
    "        return pred\n",
    "\n",
    "print(\"✓ Models implemented: Linear, DLinear, NLinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to stop training when validation loss doesn't improve\"\"\"\n",
    "    def __init__(self, patience=50, min_delta=0.0001, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose and self.counter % 10 == 0:\n",
    "                print(f'EarlyStopping counter: {self.counter}/{self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "            self.counter = 0\n",
    "    \n",
    "    def load_best_model(self, model):\n",
    "        if self.best_model_state is not None:\n",
    "            model.load_state_dict(self.best_model_state)\n",
    "\n",
    "# Training function with Early Stopping\n",
    "def train_model_with_early_stopping(\n",
    "    model, train_loader, test_loader, \n",
    "    num_epochs=1000, lr=0.001, \n",
    "    patience=50, device='cpu', verbose=True\n",
    "):\n",
    "    \"\"\"Train model with early stopping\"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=20, verbose=False\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    train_losses, test_losses = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch_x)\n",
    "            loss = criterion(preds, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        epoch_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                preds = model(batch_x)\n",
    "                loss = criterion(preds, batch_y)\n",
    "                epoch_test_loss += loss.item()\n",
    "        \n",
    "        avg_test_loss = epoch_test_loss / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        \n",
    "        scheduler.step(avg_test_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        early_stopping(avg_test_loss, model)\n",
    "        \n",
    "        if verbose and (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] - '\n",
    "                  f'Train Loss: {avg_train_loss:.6f}, '\n",
    "                  f'Test Loss: {avg_test_loss:.6f}')\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            if verbose:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    early_stopping.load_best_model(model)\n",
    "    \n",
    "    return model, train_losses, test_losses\n",
    "\n",
    "print(\"✓ Training function with Early Stopping ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            predictions.extend(outputs.cpu().numpy().flatten())\n",
    "            actuals.extend(batch_y.cpu().numpy().flatten())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    try:\n",
    "        r2 = r2_score(actuals, predictions)\n",
    "    except:\n",
    "        r2 = -999\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'predictions': predictions,\n",
    "        'actuals': actuals\n",
    "    }\n",
    "\n",
    "print(\"✓ Evaluation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "batch_size = 16\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "early_stopping_patience = 50\n",
    "\n",
    "# Storage for results\n",
    "trained_models = {}\n",
    "loss_histories = {}\n",
    "results = {}\n",
    "\n",
    "model_types = ['Linear', 'DLinear', 'NLinear']\n",
    "window_sizes = ['7d', '30d', '120d', '480d']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING ALL MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - Max Epochs: {num_epochs}\")\n",
    "print(f\"  - Early Stopping Patience: {early_stopping_patience}\")\n",
    "print(f\"  - Learning Rate: {learning_rate}\")\n",
    "print(f\"  - Batch Size: {batch_size}\")\n",
    "print(f\"  - Device: {device}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for window in window_sizes:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"WINDOW SIZE: {window}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    seq_len = int(window.replace('d', ''))\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        data_splits[window]['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        data_splits[window]['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        print(f\"\\n--- Training {model_type} with {window} input ---\")\n",
    "        \n",
    "        # Create model\n",
    "        if model_type == 'Linear':\n",
    "            model = Linear(seq_len, pred_len=1)\n",
    "        elif model_type == 'DLinear':\n",
    "            model = DLinear(seq_len, pred_len=1)\n",
    "        else:  # NLinear\n",
    "            model = NLinear(seq_len, pred_len=1)\n",
    "        \n",
    "        # Train model\n",
    "        trained_model, train_losses, test_losses = train_model_with_early_stopping(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            num_epochs=num_epochs,\n",
    "            lr=learning_rate,\n",
    "            patience=early_stopping_patience,\n",
    "            device=device,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Store model and losses\n",
    "        key = f\"{model_type}_{window}\"\n",
    "        trained_models[key] = trained_model\n",
    "        loss_histories[key] = {\n",
    "            'train': train_losses,\n",
    "            'test': test_losses\n",
    "        }\n",
    "        \n",
    "        # Evaluate\n",
    "        test_results = evaluate_model(trained_model, test_loader, device)\n",
    "        results[key] = test_results\n",
    "        \n",
    "        print(f\"Final Test RMSE: {test_results['rmse']:.4f}\")\n",
    "        print(f\"Final Test MAE: {test_results['mae']:.4f}\")\n",
    "        print(f\"Epochs trained: {len(train_losses)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ ALL MODELS TRAINED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves for all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Training and Test Loss Curves', fontsize=16, fontweight='bold')\n",
    "\n",
    "colors = {'Linear': 'red', 'DLinear': 'green', 'NLinear': 'blue'}\n",
    "\n",
    "for idx, window in enumerate(window_sizes):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        key = f\"{model_type}_{window}\"\n",
    "        train_losses = loss_histories[key]['train']\n",
    "        test_losses = loss_histories[key]['test']\n",
    "        \n",
    "        ax.plot(train_losses, \n",
    "                color=colors[model_type], \n",
    "                linewidth=1.5, \n",
    "                label=f'{model_type} - Train',\n",
    "                alpha=0.7)\n",
    "        ax.plot(test_losses, \n",
    "                color=colors[model_type], \n",
    "                linewidth=2, \n",
    "                linestyle='--',\n",
    "                label=f'{model_type} - Test',\n",
    "                alpha=0.9)\n",
    "    \n",
    "    ax.set_title(f'Loss Curves - {window} Input', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('MSE Loss')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison table\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"PERFORMANCE COMPARISON TABLE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "comparison_data = []\n",
    "for window in window_sizes:\n",
    "    for model_type in model_types:\n",
    "        key = f\"{model_type}_{window}\"\n",
    "        result = results[key]\n",
    "        comparison_data.append({\n",
    "            'Window': window,\n",
    "            'Model': model_type,\n",
    "            'RMSE': f\"{result['rmse']:.4f}\",\n",
    "            'MAE': f\"{result['mae']:.4f}\",\n",
    "            'MSE': f\"{result['mse']:.4f}\",\n",
    "            'R²': f\"{result['r2']:.4f}\",\n",
    "            'Epochs': len(loss_histories[key]['train'])\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "display(comparison_df)\n",
    "\n",
    "# Find best model\n",
    "comparison_df['RMSE_num'] = comparison_df['RMSE'].astype(float)\n",
    "best_idx = comparison_df['RMSE_num'].idxmin()\n",
    "best_model_info = comparison_df.iloc[best_idx]\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"BEST MODEL (by RMSE):\")\n",
    "print(f\"  Model: {best_model_info['Model']}\")\n",
    "print(f\"  Window: {best_model_info['Window']}\")\n",
    "print(f\"  RMSE: {best_model_info['RMSE']}\")\n",
    "print(f\"  MAE: {best_model_info['MAE']}\")\n",
    "print(f\"  R²: {best_model_info['R²']}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Test predictions vs Actual\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
    "fig.suptitle('FPT Stock Price: Test Predictions vs Actual', fontsize=18, fontweight='bold')\n",
    "\n",
    "for idx, window in enumerate(window_sizes):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Plot actual (from first model, all are same)\n",
    "    key = f\"Linear_{window}\"\n",
    "    actual = results[key]['actuals']\n",
    "    ax.plot(actual, 'black', linewidth=2, label='Actual', alpha=0.8, marker='o', markersize=2)\n",
    "    \n",
    "    # Plot predictions for each model\n",
    "    for model_type in model_types:\n",
    "        key = f\"{model_type}_{window}\"\n",
    "        preds = results[key]['predictions']\n",
    "        rmse = results[key]['rmse']\n",
    "        \n",
    "        ax.plot(preds, \n",
    "                color=colors[model_type],\n",
    "                linewidth=1.5,\n",
    "                label=f'{model_type} (RMSE: {rmse:.2f})',\n",
    "                alpha=0.7,\n",
    "                linestyle='--')\n",
    "    \n",
    "    ax.set_title(f'{window} Input Window', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Test Sample Index')\n",
    "    ax.set_ylabel('Price (VND)')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate 100-Day Future Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_autoregressive(model, initial_sequence, n_steps, device='cpu'):\n",
    "    \"\"\"\n",
    "    Autoregressive prediction: use model's own predictions to predict future\n",
    "    \n",
    "    Args:\n",
    "        model: trained model\n",
    "        initial_sequence: initial input sequence (seq_len,)\n",
    "        n_steps: number of future steps to predict\n",
    "        device: computation device\n",
    "    \n",
    "    Returns:\n",
    "        predictions: array of n_steps predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    # Start with initial sequence\n",
    "    current_seq = initial_sequence.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_steps):\n",
    "            # Prepare input\n",
    "            x = torch.FloatTensor(current_seq).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Predict next value\n",
    "            pred = model(x)\n",
    "            pred_value = pred.cpu().numpy().flatten()[0]\n",
    "            predictions.append(pred_value)\n",
    "            \n",
    "            # Update sequence: remove oldest, add newest prediction\n",
    "            current_seq = np.append(current_seq[1:], pred_value)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "print(\"✓ Autoregressive prediction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 100-day predictions for each model\n",
    "n_future_days = 100\n",
    "future_predictions = {}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENERATING 100-DAY FUTURE PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get last values from training data for each window size\n",
    "for window in window_sizes:\n",
    "    seq_len = int(window.replace('d', ''))\n",
    "    \n",
    "    # Get initial sequence (last seq_len values from training data)\n",
    "    initial_sequence = df['close'].values[-seq_len:]\n",
    "    \n",
    "    print(f\"\\nWindow {window}:\")\n",
    "    print(f\"  Initial sequence: last {seq_len} values from training data\")\n",
    "    print(f\"  Initial sequence range: [{initial_sequence.min():.2f}, {initial_sequence.max():.2f}]\")\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        key = f\"{model_type}_{window}\"\n",
    "        model = trained_models[key]\n",
    "        \n",
    "        # Generate predictions\n",
    "        preds = predict_future_autoregressive(\n",
    "            model=model,\n",
    "            initial_sequence=initial_sequence,\n",
    "            n_steps=n_future_days,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        future_predictions[key] = preds\n",
    "        \n",
    "        print(f\"  {model_type}: Generated {len(preds)} predictions\")\n",
    "        print(f\"    Prediction range: [{preds.min():.2f}, {preds.max():.2f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ All 100-day predictions generated!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create submissions directory\n",
    "os.makedirs('submissions', exist_ok=True)\n",
    "\n",
    "# Get last date from training data\n",
    "last_date = df['time'].iloc[-1]\n",
    "print(f\"Last date in training data: {last_date}\")\n",
    "print(f\"Predictions will cover: {last_date + timedelta(days=1)} to {last_date + timedelta(days=100)}\")\n",
    "\n",
    "# Save predictions for each model\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING SUBMISSION FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for window in window_sizes:\n",
    "    for model_type in model_types:\n",
    "        key = f\"{model_type}_{window}\"\n",
    "        preds = future_predictions[key]\n",
    "        \n",
    "        # Create submission dataframe\n",
    "        submission_df = pd.DataFrame({\n",
    "            'id': range(1, n_future_days + 1),\n",
    "            'close': preds\n",
    "        })\n",
    "        \n",
    "        # Save to CSV\n",
    "        filename = f'submissions/FPT_submission_{model_type}_{window}.csv'\n",
    "        submission_df.to_csv(filename, index=False)\n",
    "        \n",
    "        print(f\"✓ Saved: {filename}\")\n",
    "        print(f\"  Shape: {submission_df.shape} (101 lines including header)\")\n",
    "\n",
    "# Also save best model prediction\n",
    "best_key = f\"{best_model_info['Model']}_{best_model_info['Window']}\"\n",
    "best_preds = future_predictions[best_key]\n",
    "\n",
    "best_submission_df = pd.DataFrame({\n",
    "    'id': range(1, n_future_days + 1),\n",
    "    'close': best_preds\n",
    "})\n",
    "\n",
    "best_filename = 'submissions/FPT_submission_BEST.csv'\n",
    "best_submission_df.to_csv(best_filename, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"✓ BEST MODEL SUBMISSION: {best_filename}\")\n",
    "print(f\"  Model: {best_model_info['Model']} with {best_model_info['Window']} window\")\n",
    "print(f\"  Test RMSE: {best_model_info['RMSE']}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display sample of best submission\n",
    "print(\"\\nSample from BEST submission:\")\n",
    "display(best_submission_df.head(10))\n",
    "display(best_submission_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Future Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot historical data + future predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 14))\n",
    "fig.suptitle('FPT Stock Price: Historical + 100-Day Future Predictions', \n",
    "             fontsize=18, fontweight='bold')\n",
    "\n",
    "# Create date range for future predictions\n",
    "last_date = df['time'].iloc[-1]\n",
    "future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=n_future_days)\n",
    "\n",
    "for idx, window in enumerate(window_sizes):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Plot historical data (last 200 days)\n",
    "    historical_window = 200\n",
    "    ax.plot(df['time'].iloc[-historical_window:], \n",
    "            df['close'].iloc[-historical_window:],\n",
    "            'black', linewidth=2, label='Historical', alpha=0.8)\n",
    "    \n",
    "    # Plot future predictions for each model\n",
    "    for model_type in model_types:\n",
    "        key = f\"{model_type}_{window}\"\n",
    "        preds = future_predictions[key]\n",
    "        \n",
    "        ax.plot(future_dates, preds,\n",
    "                color=colors[model_type],\n",
    "                linewidth=2,\n",
    "                label=f'{model_type} Forecast',\n",
    "                linestyle='--',\n",
    "                alpha=0.7,\n",
    "                marker='o',\n",
    "                markersize=2)\n",
    "    \n",
    "    # Add vertical line at prediction start\n",
    "    ax.axvline(x=last_date, color='red', linestyle=':', linewidth=2, alpha=0.5)\n",
    "    ax.text(last_date, ax.get_ylim()[1], 'Forecast Start', \n",
    "            rotation=90, verticalalignment='top')\n",
    "    \n",
    "    ax.set_title(f'{window} Input Window', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price (VND)')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('submissions/FPT_forecast_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Forecast comparison plot saved: submissions/FPT_forecast_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only best model prediction\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Historical data\n",
    "ax.plot(df['time'], df['close'], \n",
    "        'blue', linewidth=2, label='Historical Data', alpha=0.8)\n",
    "\n",
    "# Best model prediction\n",
    "best_key = f\"{best_model_info['Model']}_{best_model_info['Window']}\"\n",
    "best_preds = future_predictions[best_key]\n",
    "\n",
    "ax.plot(future_dates, best_preds,\n",
    "        'red', linewidth=2.5, label=f\"100-Day Forecast ({best_model_info['Model']} - {best_model_info['Window']})\",\n",
    "        linestyle='--', marker='o', markersize=3, alpha=0.9)\n",
    "\n",
    "# Add prediction interval shading (simple ±10% bands)\n",
    "upper_band = best_preds * 1.1\n",
    "lower_band = best_preds * 0.9\n",
    "ax.fill_between(future_dates, lower_band, upper_band, alpha=0.2, color='red')\n",
    "\n",
    "# Vertical line at forecast start\n",
    "ax.axvline(x=last_date, color='green', linestyle=':', linewidth=2, alpha=0.7)\n",
    "ax.text(last_date, ax.get_ylim()[1]*0.95, 'Forecast Start →', \n",
    "        fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_title(f'FPT Stock Price: Best Model 100-Day Forecast\\n'\n",
    "             f'Model: {best_model_info[\"Model\"]} | Window: {best_model_info[\"Window\"]} | '\n",
    "             f'Test RMSE: {best_model_info[\"RMSE\"]}',\n",
    "             fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Price (VND)', fontsize=12)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('submissions/FPT_best_forecast.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Best model forecast plot saved: submissions/FPT_best_forecast.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for all predictions\n",
    "print(\"=\"*100)\n",
    "print(\"PREDICTION SUMMARY STATISTICS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "summary_stats = []\n",
    "for window in window_sizes:\n",
    "    for model_type in model_types:\n",
    "        key = f\"{model_type}_{window}\"\n",
    "        preds = future_predictions[key]\n",
    "        \n",
    "        summary_stats.append({\n",
    "            'Model': model_type,\n",
    "            'Window': window,\n",
    "            'Mean': f\"{preds.mean():.2f}\",\n",
    "            'Std': f\"{preds.std():.2f}\",\n",
    "            'Min': f\"{preds.min():.2f}\",\n",
    "            'Max': f\"{preds.max():.2f}\",\n",
    "            'Trend': 'Up' if preds[-1] > preds[0] else 'Down',\n",
    "            'Change%': f\"{((preds[-1] - preds[0]) / preds[0] * 100):.2f}%\"\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "display(summary_df)\n",
    "\n",
    "# Historical comparison\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"HISTORICAL DATA REFERENCE\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Last price in training data: {df['close'].iloc[-1]:.2f} VND\")\n",
    "print(f\"Training data mean: {df['close'].mean():.2f} VND\")\n",
    "print(f\"Training data std: {df['close'].std():.2f} VND\")\n",
    "print(f\"Training data range: [{df['close'].min():.2f}, {df['close'].max():.2f}]\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(f\"✓ Trained {len(model_types)} model types with {len(window_sizes)} window sizes\")\n",
    "print(f\"✓ Total models trained: {len(trained_models)}\")\n",
    "print(f\"✓ Generated {n_future_days}-day predictions for all models\")\n",
    "print(f\"✓ All submission files saved to: submissions/\")\n",
    "print(f\"\\nBest Model: {best_model_info['Model']} with {best_model_info['Window']} window\")\n",
    "print(f\"  - Test RMSE: {best_model_info['RMSE']}\")\n",
    "print(f\"  - Test MAE: {best_model_info['MAE']}\")\n",
    "print(f\"  - R²: {best_model_info['R²']}\")\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
