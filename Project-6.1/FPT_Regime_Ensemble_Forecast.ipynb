{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ FPT Stock Forecasting with Market Regime-based Ensemble\n",
    "\n",
    "## Approach\n",
    "1. **Split data TR∆Ø·ªöC** ƒë·ªÉ tr√°nh data leakage\n",
    "2. **HMM Regime Detection** v·ªõi 60-day window (train tr√™n train set)\n",
    "3. **Ensemble Models** (Linear + DLinear + NLinear) cho t·ª´ng regime\n",
    "4. **Predict 100 ng√†y** ti·∫øp theo\n",
    "\n",
    "## Key Anti-Leakage Measures\n",
    "- Scaler fit tr√™n train only\n",
    "- HMM fit tr√™n train only\n",
    "- Regime assignment d√πng model ƒë√£ train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hmmlearn import hmm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data & Split FIRST (Anti-Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/FPT_train.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df = df.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Date range: {df['time'].min().date()} ‚Üí {df['time'].max().date()}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è SPLIT FIRST - Anti-leakage\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "# test_ratio = 0.15 (implicit)\n",
    "\n",
    "n_total = len(df)\n",
    "train_end = int(n_total * train_ratio)\n",
    "val_end = int(n_total * (train_ratio + val_ratio))\n",
    "\n",
    "df_train = df.iloc[:train_end].copy()\n",
    "df_val = df.iloc[train_end:val_end].copy()\n",
    "df_test = df.iloc[val_end:].copy()\n",
    "\n",
    "print(f\"Train: {len(df_train)} ({df_train['time'].min().date()} ‚Üí {df_train['time'].max().date()})\")\n",
    "print(f\"Val:   {len(df_val)} ({df_val['time'].min().date()} ‚Üí {df_val['time'].max().date()})\")\n",
    "print(f\"Test:  {len(df_test)} ({df_test['time'].min().date()} ‚Üí {df_test['time'].max().date()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering & Scaling (Train Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(data):\n",
    "    \"\"\"Add log transforms and technical features\"\"\"\n",
    "    data = data.copy()\n",
    "    data['close_log'] = np.log(data['close'])\n",
    "    data['open_log'] = np.log(data['open'])\n",
    "    data['high_log'] = np.log(data['high'])\n",
    "    data['low_log'] = np.log(data['low'])\n",
    "    data['volume_log'] = np.log(data['volume'] + 1)\n",
    "    data['hl_spread'] = (data['high'] - data['low']) / data['close']\n",
    "    data['oc_spread'] = (data['close'] - data['open']) / data['open']\n",
    "    return data\n",
    "\n",
    "# Apply to all splits\n",
    "df_train = add_features(df_train)\n",
    "df_val = add_features(df_val)\n",
    "df_test = add_features(df_test)\n",
    "\n",
    "# Also keep full df for later\n",
    "df_full = add_features(df)\n",
    "\n",
    "print(\"Features added!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è FIT SCALER ON TRAIN ONLY\n",
    "uni_scaler = StandardScaler()\n",
    "uni_scaler.fit(df_train['close_log'].values.reshape(-1, 1))\n",
    "\n",
    "# Transform all\n",
    "df_train['close_scaled'] = uni_scaler.transform(df_train['close_log'].values.reshape(-1, 1)).flatten()\n",
    "df_val['close_scaled'] = uni_scaler.transform(df_val['close_log'].values.reshape(-1, 1)).flatten()\n",
    "df_test['close_scaled'] = uni_scaler.transform(df_test['close_log'].values.reshape(-1, 1)).flatten()\n",
    "df_full['close_scaled'] = uni_scaler.transform(df_full['close_log'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"Scaler mean: {uni_scaler.mean_[0]:.4f}, std: {uni_scaler.scale_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HMM Regime Detection (Fit on Train Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regime_features(data, window=60):\n",
    "    \"\"\"Compute features for regime detection\"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Return in window days\n",
    "    data['return'] = data['close'].pct_change(window) * 100\n",
    "    \n",
    "    # Volatility (annualized)\n",
    "    data['daily_ret'] = data['close'].pct_change()\n",
    "    data['volatility'] = data['daily_ret'].rolling(window).std() * np.sqrt(252) * 100\n",
    "    \n",
    "    # Trend\n",
    "    def calc_trend(series):\n",
    "        x = np.arange(len(series))\n",
    "        slope = np.polyfit(x, series, 1)[0]\n",
    "        return slope / series.mean() * 100\n",
    "    \n",
    "    data['trend'] = data['close'].rolling(window).apply(calc_trend, raw=False)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Compute regime features\n",
    "REGIME_WINDOW = 60\n",
    "df_train_regime = compute_regime_features(df_train, REGIME_WINDOW)\n",
    "df_full_regime = compute_regime_features(df_full, REGIME_WINDOW)\n",
    "\n",
    "# Drop NaN for HMM training\n",
    "df_train_regime_clean = df_train_regime.dropna().copy()\n",
    "df_full_regime_clean = df_full_regime.dropna().copy()\n",
    "\n",
    "print(f\"Train regime samples: {len(df_train_regime_clean)}\")\n",
    "print(f\"Full regime samples: {len(df_full_regime_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è FIT HMM ON TRAIN ONLY\n",
    "regime_features = ['return', 'volatility', 'trend']\n",
    "\n",
    "# Prepare train data\n",
    "X_train_regime = df_train_regime_clean[regime_features].values\n",
    "\n",
    "# Scale regime features (fit on train)\n",
    "regime_scaler = StandardScaler()\n",
    "X_train_regime_scaled = regime_scaler.fit_transform(X_train_regime)\n",
    "\n",
    "# Fit HMM\n",
    "N_REGIMES = 4\n",
    "hmm_model = hmm.GaussianHMM(\n",
    "    n_components=N_REGIMES,\n",
    "    covariance_type=\"full\",\n",
    "    n_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "hmm_model.fit(X_train_regime_scaled)\n",
    "\n",
    "print(f\"HMM trained with {N_REGIMES} regimes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict regimes for ALL data (using trained HMM)\n",
    "X_full_regime = df_full_regime_clean[regime_features].values\n",
    "X_full_regime_scaled = regime_scaler.transform(X_full_regime)\n",
    "\n",
    "# Predict\n",
    "regimes_full = hmm_model.predict(X_full_regime_scaled)\n",
    "df_full_regime_clean['regime'] = regimes_full\n",
    "\n",
    "# Analyze regimes\n",
    "regime_stats = df_full_regime_clean.groupby('regime').agg({\n",
    "    'return': 'mean',\n",
    "    'volatility': 'mean'\n",
    "})\n",
    "\n",
    "# Sort by return and assign names\n",
    "sorted_regimes = regime_stats['return'].sort_values(ascending=False).index.tolist()\n",
    "regime_names = {sorted_regimes[0]: 'Rally', sorted_regimes[1]: 'Uptrend', \n",
    "                sorted_regimes[2]: 'Sideway', sorted_regimes[3]: 'Downtrend'}\n",
    "regime_colors = {sorted_regimes[0]: '#1B5E20', sorted_regimes[1]: '#4CAF50',\n",
    "                 sorted_regimes[2]: '#9E9E9E', sorted_regimes[3]: '#C62828'}\n",
    "\n",
    "df_full_regime_clean['regime_name'] = df_full_regime_clean['regime'].map(regime_names)\n",
    "\n",
    "print(\"\\nRegime Analysis:\")\n",
    "for regime in sorted_regimes:\n",
    "    count = (df_full_regime_clean['regime'] == regime).sum()\n",
    "    pct = count / len(df_full_regime_clean) * 100\n",
    "    ret = regime_stats.loc[regime, 'return']\n",
    "    vol = regime_stats.loc[regime, 'volatility']\n",
    "    print(f\"  {regime_names[regime]}: {pct:.1f}% | Return: {ret:+.1f}% | Vol: {vol:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regimes\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "for regime in sorted_regimes:\n",
    "    mask = df_full_regime_clean['regime'] == regime\n",
    "    ax.scatter(df_full_regime_clean.loc[mask, 'time'],\n",
    "               df_full_regime_clean.loc[mask, 'close'],\n",
    "               c=regime_colors[regime], label=regime_names[regime],\n",
    "               alpha=0.6, s=15)\n",
    "\n",
    "ax.set_title('FPT Stock with Market Regimes (HMM 60-day)', fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Price (VND)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Models\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(seq_len, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class NLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(seq_len, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        last = x[:, -1:]\n",
    "        return self.fc(x - last) + last\n",
    "\n",
    "\n",
    "class DLinear(nn.Module):\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.kernel_size = max(3, seq_len // 4)\n",
    "        self.fc_trend = nn.Linear(seq_len, pred_len)\n",
    "        self.fc_seasonal = nn.Linear(seq_len, pred_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        trend = x.unfold(-1, self.kernel_size, 1).mean(-1)\n",
    "        pad_left = (self.seq_len - trend.size(-1)) // 2\n",
    "        pad_right = self.seq_len - trend.size(-1) - pad_left\n",
    "        trend = F.pad(trend, (pad_left, pad_right), mode='replicate')\n",
    "        seasonal = x - trend\n",
    "        return self.fc_trend(trend) + self.fc_seasonal(seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regime-specific Ensemble\n",
    "class RegimeEnsemble(nn.Module):\n",
    "    \"\"\"Ensemble of Linear + DLinear + NLinear with learnable weights\"\"\"\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(seq_len, pred_len)\n",
    "        self.dlinear = DLinear(seq_len, pred_len)\n",
    "        self.nlinear = NLinear(seq_len, pred_len)\n",
    "        self.weights = nn.Parameter(torch.ones(3) / 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        p1 = self.linear(x)\n",
    "        p2 = self.dlinear(x)\n",
    "        p3 = self.nlinear(x)\n",
    "        w = F.softmax(self.weights, dim=0)\n",
    "        return w[0] * p1 + w[1] * p2 + w[2] * p3\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return F.softmax(self.weights, dim=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset & Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, series, regimes, seq_len, pred_len, target_regime=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            series: price data (scaled)\n",
    "            regimes: regime labels for each timestep\n",
    "            target_regime: if specified, only use samples from this regime\n",
    "        \"\"\"\n",
    "        self.series = series.astype(np.float32)\n",
    "        self.regimes = regimes\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.target_regime = target_regime\n",
    "        \n",
    "        # Find valid indices\n",
    "        self.valid_indices = []\n",
    "        for i in range(len(self.series) - seq_len - pred_len + 1):\n",
    "            if target_regime is None:\n",
    "                self.valid_indices.append(i)\n",
    "            else:\n",
    "                # Check if the END of input sequence is in target regime\n",
    "                if i + seq_len - 1 < len(regimes) and regimes[i + seq_len - 1] == target_regime:\n",
    "                    self.valid_indices.append(i)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i = self.valid_indices[idx]\n",
    "        x = self.series[i: i + self.seq_len]\n",
    "        y = self.series[i + self.seq_len: i + self.seq_len + self.pred_len]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, lr, patience, device):\n",
    "    \"\"\"Train model with early stopping\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                pred = model(x)\n",
    "                val_loss += criterion(pred, y).item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            pred = model(x).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            targets.append(y.numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(targets.flatten(), preds.flatten()))\n",
    "    mae = mean_absolute_error(targets.flatten(), preds.flatten())\n",
    "    \n",
    "    return rmse, mae, preds, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Ensemble Model for Each Regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "SEQ_LEN = 60  # Match regime window\n",
    "PRED_LEN = 100\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 300\n",
    "PATIENCE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "# Prepare data with regimes\n",
    "# Merge regimes back to full dataframe\n",
    "series_full = df_full_regime_clean['close_scaled'].values\n",
    "regimes_full_arr = df_full_regime_clean['regime'].values\n",
    "times_full = df_full_regime_clean['time'].values\n",
    "\n",
    "# Get train/val/test indices based on time\n",
    "train_end_time = df_train['time'].max()\n",
    "val_end_time = df_val['time'].max()\n",
    "\n",
    "train_mask = df_full_regime_clean['time'] <= train_end_time\n",
    "val_mask = (df_full_regime_clean['time'] > train_end_time) & (df_full_regime_clean['time'] <= val_end_time)\n",
    "test_mask = df_full_regime_clean['time'] > val_end_time\n",
    "\n",
    "print(f\"Train samples (with regime): {train_mask.sum()}\")\n",
    "print(f\"Val samples: {val_mask.sum()}\")\n",
    "print(f\"Test samples: {test_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ensemble for each regime\n",
    "regime_models = {}\n",
    "regime_results = []\n",
    "\n",
    "for regime in sorted_regimes:\n",
    "    regime_name = regime_names[regime]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Ensemble for Regime: {regime_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create dataset for this regime\n",
    "    dataset = TimeSeriesDataset(\n",
    "        series_full, regimes_full_arr, SEQ_LEN, PRED_LEN, target_regime=regime\n",
    "    )\n",
    "    \n",
    "    if len(dataset) < 10:\n",
    "        print(f\"  ‚ö†Ô∏è Not enough samples ({len(dataset)}), skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Split into train/val\n",
    "    total = len(dataset)\n",
    "    train_len = int(total * 0.8)\n",
    "    \n",
    "    train_subset = torch.utils.data.Subset(dataset, list(range(train_len)))\n",
    "    val_subset = torch.utils.data.Subset(dataset, list(range(train_len, total)))\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    print(f\"  Samples: {len(dataset)} (train: {train_len}, val: {total - train_len})\")\n",
    "    \n",
    "    # Create and train model\n",
    "    model = RegimeEnsemble(SEQ_LEN, PRED_LEN)\n",
    "    model = train_model(model, train_loader, val_loader, NUM_EPOCHS, LR, PATIENCE, device)\n",
    "    \n",
    "    # Get ensemble weights\n",
    "    weights = model.get_weights()\n",
    "    print(f\"  Weights: Linear={weights[0]:.3f}, DLinear={weights[1]:.3f}, NLinear={weights[2]:.3f}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    rmse, mae, _, _ = evaluate_model(model, val_loader, device)\n",
    "    print(f\"  Val RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "    \n",
    "    regime_models[regime] = model\n",
    "    regime_results.append({\n",
    "        'Regime': regime_name,\n",
    "        'Samples': len(dataset),\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'Linear_W': weights[0],\n",
    "        'DLinear_W': weights[1],\n",
    "        'NLinear_W': weights[2]\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "results_df = pd.DataFrame(regime_results)\n",
    "print(\"\\nRegime Model Results:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Global Ensemble (All Data) for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global model (no regime filtering)\n",
    "print(\"\\nTraining Global Ensemble (all regimes combined)...\")\n",
    "\n",
    "global_dataset = TimeSeriesDataset(\n",
    "    series_full, regimes_full_arr, SEQ_LEN, PRED_LEN, target_regime=None\n",
    ")\n",
    "\n",
    "total = len(global_dataset)\n",
    "train_len = int(total * 0.8)\n",
    "\n",
    "train_subset = torch.utils.data.Subset(global_dataset, list(range(train_len)))\n",
    "val_subset = torch.utils.data.Subset(global_dataset, list(range(train_len, total)))\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE)\n",
    "\n",
    "global_model = RegimeEnsemble(SEQ_LEN, PRED_LEN)\n",
    "global_model = train_model(global_model, train_loader, val_loader, NUM_EPOCHS, LR, PATIENCE, device)\n",
    "\n",
    "global_weights = global_model.get_weights()\n",
    "global_rmse, global_mae, _, _ = evaluate_model(global_model, val_loader, device)\n",
    "\n",
    "print(f\"Global Ensemble:\")\n",
    "print(f\"  Samples: {len(global_dataset)}\")\n",
    "print(f\"  Weights: Linear={global_weights[0]:.3f}, DLinear={global_weights[1]:.3f}, NLinear={global_weights[2]:.3f}\")\n",
    "print(f\"  Val RMSE: {global_rmse:.4f}, MAE: {global_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Retrain Best Models on Full Data & Generate Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain all regime models on 90% of their data\n",
    "print(\"\\nRetraining regime models on 90% data...\")\n",
    "\n",
    "final_regime_models = {}\n",
    "\n",
    "for regime in sorted_regimes:\n",
    "    if regime not in regime_models:\n",
    "        continue\n",
    "    \n",
    "    regime_name = regime_names[regime]\n",
    "    \n",
    "    dataset = TimeSeriesDataset(\n",
    "        series_full, regimes_full_arr, SEQ_LEN, PRED_LEN, target_regime=regime\n",
    "    )\n",
    "    \n",
    "    if len(dataset) < 10:\n",
    "        continue\n",
    "    \n",
    "    total = len(dataset)\n",
    "    train_len = int(total * 0.9)\n",
    "    \n",
    "    train_subset = torch.utils.data.Subset(dataset, list(range(train_len)))\n",
    "    val_subset = torch.utils.data.Subset(dataset, list(range(train_len, total)))\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = RegimeEnsemble(SEQ_LEN, PRED_LEN)\n",
    "    model = train_model(model, train_loader, val_loader, NUM_EPOCHS, LR, PATIENCE, device)\n",
    "    \n",
    "    final_regime_models[regime] = model\n",
    "    print(f\"  {regime_name}: ‚úì\")\n",
    "\n",
    "# Also retrain global model\n",
    "total = len(global_dataset)\n",
    "train_len = int(total * 0.9)\n",
    "train_subset = torch.utils.data.Subset(global_dataset, list(range(train_len)))\n",
    "val_subset = torch.utils.data.Subset(global_dataset, list(range(train_len, total)))\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE)\n",
    "\n",
    "final_global_model = RegimeEnsemble(SEQ_LEN, PRED_LEN)\n",
    "final_global_model = train_model(final_global_model, train_loader, val_loader, NUM_EPOCHS, LR, PATIENCE, device)\n",
    "print(\"  Global: ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_future(model, input_data, scaler, device):\n",
    "    \"\"\"Generate forecast for future\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = torch.from_numpy(input_data.astype(np.float32)).unsqueeze(0).to(device)\n",
    "        pred_scaled = model(x).cpu().numpy().flatten()\n",
    "    \n",
    "    # Inverse transform\n",
    "    pred_log = scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
    "    pred_price = np.exp(pred_log)\n",
    "    \n",
    "    return pred_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine current regime\n",
    "current_regime = regimes_full_arr[-1]\n",
    "current_regime_name = regime_names[current_regime]\n",
    "print(f\"\\nCurrent market regime: {current_regime_name}\")\n",
    "\n",
    "# Get last SEQ_LEN data\n",
    "input_data = series_full[-SEQ_LEN:]\n",
    "\n",
    "# Generate forecasts from both regime-specific and global models\n",
    "print(\"\\nGenerating 100-day forecasts...\")\n",
    "\n",
    "# Regime-specific forecast\n",
    "if current_regime in final_regime_models:\n",
    "    regime_forecast = forecast_future(final_regime_models[current_regime], input_data, uni_scaler, device)\n",
    "    print(f\"  Regime ({current_regime_name}) forecast: {regime_forecast[0]:.2f} ‚Üí {regime_forecast[-1]:.2f}\")\n",
    "else:\n",
    "    regime_forecast = None\n",
    "    print(f\"  ‚ö†Ô∏è No model for regime {current_regime_name}\")\n",
    "\n",
    "# Global forecast\n",
    "global_forecast = forecast_future(final_global_model, input_data, uni_scaler, device)\n",
    "print(f\"  Global forecast: {global_forecast[0]:.2f} ‚Üí {global_forecast[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best forecast (regime-specific if available)\n",
    "if regime_forecast is not None:\n",
    "    final_forecast = regime_forecast\n",
    "    forecast_type = f\"Regime-{current_regime_name}\"\n",
    "else:\n",
    "    final_forecast = global_forecast\n",
    "    forecast_type = \"Global\"\n",
    "\n",
    "print(f\"\\nUsing {forecast_type} forecast\")\n",
    "print(f\"Forecast range: {final_forecast.min():.2f} - {final_forecast.max():.2f} VND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': np.arange(1, PRED_LEN + 1),\n",
    "    'close': final_forecast\n",
    "})\n",
    "\n",
    "# Save\n",
    "os.makedirs('submissions', exist_ok=True)\n",
    "submission_path = f'submissions/submission_regime_ensemble_{current_regime_name.lower()}.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Submission saved: {submission_path}\")\n",
    "print(f\"Rows: {len(submission)}\")\n",
    "print(\"\\nPreview:\")\n",
    "display(submission.head(10))\n",
    "display(submission.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save global forecast for comparison\n",
    "submission_global = pd.DataFrame({\n",
    "    'id': np.arange(1, PRED_LEN + 1),\n",
    "    'close': global_forecast\n",
    "})\n",
    "submission_global.to_csv('submissions/submission_global_ensemble.csv', index=False)\n",
    "print(\"Also saved: submissions/submission_global_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot historical + forecast\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Full history with regimes\n",
    "ax = axes[0]\n",
    "for regime in sorted_regimes:\n",
    "    mask = df_full_regime_clean['regime'] == regime\n",
    "    ax.scatter(df_full_regime_clean.loc[mask, 'time'],\n",
    "               df_full_regime_clean.loc[mask, 'close'],\n",
    "               c=regime_colors[regime], label=regime_names[regime],\n",
    "               alpha=0.5, s=10)\n",
    "\n",
    "ax.set_title('FPT Stock with Market Regimes', fontweight='bold')\n",
    "ax.set_ylabel('Price (VND)')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Recent history + forecast\n",
    "ax = axes[1]\n",
    "\n",
    "hist_days = 150\n",
    "hist_dates = df_full_regime_clean['time'].iloc[-hist_days:]\n",
    "hist_prices = df_full_regime_clean['close'].iloc[-hist_days:]\n",
    "\n",
    "# Future dates\n",
    "last_date = df_full_regime_clean['time'].iloc[-1]\n",
    "future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=PRED_LEN, freq='B')\n",
    "\n",
    "ax.plot(hist_dates, hist_prices, 'b-', linewidth=2, label='Historical')\n",
    "ax.plot(future_dates, final_forecast, 'r--', linewidth=2, label=f'Forecast ({forecast_type})')\n",
    "\n",
    "if regime_forecast is not None and not np.array_equal(regime_forecast, global_forecast):\n",
    "    ax.plot(future_dates, global_forecast, 'g:', linewidth=1.5, alpha=0.7, label='Global Ensemble')\n",
    "\n",
    "ax.axvline(last_date, color='gray', linestyle=':', alpha=0.7, label='Forecast start')\n",
    "\n",
    "ax.set_title(f'100-Day Forecast (Current Regime: {current_regime_name})', fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Price (VND)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('submissions/forecast_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nData: FPT Stock ({df['time'].min().date()} ‚Üí {df['time'].max().date()})\")\n",
    "print(f\"Regime Window: {REGIME_WINDOW} days\")\n",
    "print(f\"Sequence Length: {SEQ_LEN} days\")\n",
    "print(f\"Prediction Length: {PRED_LEN} days\")\n",
    "print(f\"\\nCurrent Regime: {current_regime_name}\")\n",
    "print(f\"Forecast Type: {forecast_type}\")\n",
    "print(f\"\\nForecast Statistics:\")\n",
    "print(f\"  Start: {final_forecast[0]:.2f} VND\")\n",
    "print(f\"  End: {final_forecast[-1]:.2f} VND\")\n",
    "print(f\"  Min: {final_forecast.min():.2f} VND\")\n",
    "print(f\"  Max: {final_forecast.max():.2f} VND\")\n",
    "print(f\"  Mean: {final_forecast.mean():.2f} VND\")\n",
    "print(f\"\\nSubmission: {submission_path}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
