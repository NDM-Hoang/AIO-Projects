{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Optimization & Selection\n",
        "\n",
        "Comprehensive model training, hyperparameter tuning, and selection for house price prediction.\n",
        "\n",
        "## Overview\n",
        "- Linear models: Ridge, Lasso, ElasticNet with regularization\n",
        "- Tree-based models: LightGBM, XGBoost\n",
        "- 5-Fold Cross-Validation for model selection\n",
        "- Comprehensive evaluation metrics\n",
        "\n",
        "## Data\n",
        "- Train: 1239 samples (85%)\n",
        "- Test: 219 samples (15%)\n",
        "- Features: 176 numeric features (already encoded and scaled)\n",
        "- Target: SalePrice (log-transformed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Tree-based models\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    LIGHTGBM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LIGHTGBM_AVAILABLE = False\n",
        "    print(\"LightGBM not available. Install with: pip install lightgbm\")\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n",
        "print(f\"LightGBM available: {LIGHTGBM_AVAILABLE}\")\n",
        "print(f\"XGBoost available: {XGBOOST_AVAILABLE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data\n",
        "train_df = pd.read_csv('../data/processed/train_encoded.csv')\n",
        "test_df = pd.read_csv('../data/processed/test_encoded.csv')\n",
        "\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "print(f\"Features: {train_df.shape[1] - 1}\")\n",
        "print(f\"Target: SalePrice\")\n",
        "\n",
        "# Separate features and target\n",
        "X_train = train_df.drop('SalePrice', axis=1)\n",
        "y_train = train_df['SalePrice']\n",
        "X_test = test_df.drop('SalePrice', axis=1)\n",
        "y_test = test_df['SalePrice']\n",
        "\n",
        "print(f\"\\n‚úÖ Data loaded successfully\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "\n",
        "# Check for any missing values\n",
        "print(f\"\\nMissing values:\")\n",
        "print(f\"X_train: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"y_train: {y_train.isnull().sum()}\")\n",
        "print(f\"X_test: {X_test.isnull().sum().sum()}\")\n",
        "print(f\"y_test: {y_test.isnull().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define evaluation metrics\n",
        "def calculate_metrics(y_true, y_pred, model_name=\"Model\"):\n",
        "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    # RMSLE (Root Mean Squared Log Error) - commonly used for house price prediction\n",
        "    # Since target is already log-transformed, we calculate RMSLE differently\n",
        "    rmsle = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    \n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'R¬≤': r2,\n",
        "        'RMSLE': rmsle\n",
        "    }\n",
        "\n",
        "def cross_validate_model(model, X, y, cv_folds=5, model_name=\"Model\"):\n",
        "    \"\"\"Perform cross-validation and return mean scores\"\"\"\n",
        "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "    \n",
        "    rmse_scores = []\n",
        "    mae_scores = []\n",
        "    r2_scores = []\n",
        "    \n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "        \n",
        "        model.fit(X_fold_train, y_fold_train)\n",
        "        y_pred = model.predict(X_fold_val)\n",
        "        \n",
        "        rmse_scores.append(np.sqrt(mean_squared_error(y_fold_val, y_pred)))\n",
        "        mae_scores.append(mean_absolute_error(y_fold_val, y_pred))\n",
        "        r2_scores.append(r2_score(y_fold_val, y_pred))\n",
        "    \n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'CV_RMSE_mean': np.mean(rmse_scores),\n",
        "        'CV_RMSE_std': np.std(rmse_scores),\n",
        "        'CV_MAE_mean': np.mean(mae_scores),\n",
        "        'CV_MAE_std': np.std(mae_scores),\n",
        "        'CV_R¬≤_mean': np.mean(r2_scores),\n",
        "        'CV_R¬≤_std': np.std(r2_scores)\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Evaluation functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Linear Models with Regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define hyperparameter grids for linear models\n",
        "ridge_params = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1, 10, 50, 100]\n",
        "}\n",
        "\n",
        "lasso_params = {\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "elasticnet_params = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1],\n",
        "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "}\n",
        "\n",
        "# Initialize models\n",
        "ridge_model = Ridge(random_state=42)\n",
        "lasso_model = Lasso(random_state=42, max_iter=2000)\n",
        "elasticnet_model = ElasticNet(random_state=42, max_iter=2000)\n",
        "\n",
        "print(\"‚úÖ Linear models initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Ridge Regression\n",
        "print(\"Training Ridge Regression...\")\n",
        "ridge_search = GridSearchCV(\n",
        "    ridge_model, ridge_params, \n",
        "    cv=5, scoring='neg_mean_squared_error', \n",
        "    n_jobs=-1, verbose=1\n",
        ")\n",
        "ridge_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Ridge alpha: {ridge_search.best_params_['alpha']}\")\n",
        "print(f\"Best Ridge CV score: {-ridge_search.best_score_:.6f}\")\n",
        "\n",
        "# Train Lasso Regression\n",
        "print(\"\\nTraining Lasso Regression...\")\n",
        "lasso_search = GridSearchCV(\n",
        "    lasso_model, lasso_params, \n",
        "    cv=5, scoring='neg_mean_squared_error', \n",
        "    n_jobs=-1, verbose=1\n",
        ")\n",
        "lasso_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Lasso alpha: {lasso_search.best_params_['alpha']}\")\n",
        "print(f\"Best Lasso CV score: {-lasso_search.best_score_:.6f}\")\n",
        "\n",
        "# Train ElasticNet\n",
        "print(\"\\nTraining ElasticNet...\")\n",
        "elasticnet_search = GridSearchCV(\n",
        "    elasticnet_model, elasticnet_params, \n",
        "    cv=5, scoring='neg_mean_squared_error', \n",
        "    n_jobs=-1, verbose=1\n",
        ")\n",
        "elasticnet_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best ElasticNet params: {elasticnet_search.best_params_}\")\n",
        "print(f\"Best ElasticNet CV score: {-elasticnet_search.best_score_:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate linear models on test set\n",
        "linear_results = []\n",
        "\n",
        "# Ridge\n",
        "ridge_pred = ridge_search.predict(X_test)\n",
        "ridge_metrics = calculate_metrics(y_test, ridge_pred, \"Ridge\")\n",
        "ridge_metrics.update({\n",
        "    'Best_Params': ridge_search.best_params_,\n",
        "    'CV_Score': -ridge_search.best_score_\n",
        "})\n",
        "linear_results.append(ridge_metrics)\n",
        "\n",
        "# Lasso\n",
        "lasso_pred = lasso_search.predict(X_test)\n",
        "lasso_metrics = calculate_metrics(y_test, lasso_pred, \"Lasso\")\n",
        "lasso_metrics.update({\n",
        "    'Best_Params': lasso_search.best_params_,\n",
        "    'CV_Score': -lasso_search.best_score_\n",
        "})\n",
        "linear_results.append(lasso_metrics)\n",
        "\n",
        "# ElasticNet\n",
        "elasticnet_pred = elasticnet_search.predict(X_test)\n",
        "elasticnet_metrics = calculate_metrics(y_test, elasticnet_pred, \"ElasticNet\")\n",
        "elasticnet_metrics.update({\n",
        "    'Best_Params': elasticnet_search.best_params_,\n",
        "    'CV_Score': -elasticnet_search.best_score_\n",
        "})\n",
        "linear_results.append(elasticnet_metrics)\n",
        "\n",
        "# Display results\n",
        "linear_df = pd.DataFrame(linear_results)\n",
        "print(\"\\nüìä Linear Models Results:\")\n",
        "print(linear_df[['Model', 'RMSE', 'MAE', 'R¬≤', 'CV_Score']].round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Tree-Based Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define hyperparameter grids for tree-based models\n",
        "if LIGHTGBM_AVAILABLE:\n",
        "    lgb_params = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "        'num_leaves': [31, 50, 100, 200],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples': [20, 50, 100],\n",
        "        'subsample': [0.8, 0.9, 1.0],\n",
        "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "    }\n",
        "\n",
        "if XGBOOST_AVAILABLE:\n",
        "    xgb_params = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.8, 0.9, 1.0],\n",
        "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "        'gamma': [0, 0.1, 0.2]\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Tree-based model parameters defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree_results = []\n",
        "\n",
        "# Train LightGBM\n",
        "if LIGHTGBM_AVAILABLE:\n",
        "    print(\"Training LightGBM...\")\n",
        "    lgb_model = lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
        "    \n",
        "    lgb_search = RandomizedSearchCV(\n",
        "        lgb_model, lgb_params, \n",
        "        n_iter=30, cv=5, scoring='neg_mean_squared_error', \n",
        "        n_jobs=-1, random_state=42, verbose=1\n",
        "    )\n",
        "    lgb_search.fit(X_train, y_train)\n",
        "    \n",
        "    print(f\"Best LightGBM params: {lgb_search.best_params_}\")\n",
        "    print(f\"Best LightGBM CV score: {-lgb_search.best_score_:.6f}\")\n",
        "    \n",
        "    # Evaluate\n",
        "    lgb_pred = lgb_search.predict(X_test)\n",
        "    lgb_metrics = calculate_metrics(y_test, lgb_pred, \"LightGBM\")\n",
        "    lgb_metrics.update({\n",
        "        'Best_Params': lgb_search.best_params_,\n",
        "        'CV_Score': -lgb_search.best_score_\n",
        "    })\n",
        "    tree_results.append(lgb_metrics)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è LightGBM not available\")\n",
        "\n",
        "# Train XGBoost\n",
        "if XGBOOST_AVAILABLE:\n",
        "    print(\"\\nTraining XGBoost...\")\n",
        "    xgb_model = xgb.XGBRegressor(random_state=42, verbosity=0)\n",
        "    \n",
        "    xgb_search = RandomizedSearchCV(\n",
        "        xgb_model, xgb_params, \n",
        "        n_iter=30, cv=5, scoring='neg_mean_squared_error', \n",
        "        n_jobs=-1, random_state=42, verbose=1\n",
        "    )\n",
        "    xgb_search.fit(X_train, y_train)\n",
        "    \n",
        "    print(f\"Best XGBoost params: {xgb_search.best_params_}\")\n",
        "    print(f\"Best XGBoost CV score: {-xgb_search.best_score_:.6f}\")\n",
        "    \n",
        "    # Evaluate\n",
        "    xgb_pred = xgb_search.predict(X_test)\n",
        "    xgb_metrics = calculate_metrics(y_test, xgb_pred, \"XGBoost\")\n",
        "    xgb_metrics.update({\n",
        "        'Best_Params': xgb_search.best_params_,\n",
        "        'CV_Score': -xgb_search.best_score_\n",
        "    })\n",
        "    tree_results.append(xgb_metrics)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è XGBoost not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display tree-based results\n",
        "if tree_results:\n",
        "    tree_df = pd.DataFrame(tree_results)\n",
        "    print(\"\\nüìä Tree-Based Models Results:\")\n",
        "    print(tree_df[['Model', 'RMSE', 'MAE', 'R¬≤', 'CV_Score']].round(4))\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No tree-based models trained (dependencies not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Comparison & Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all results\n",
        "all_results = linear_results + tree_results\n",
        "results_df = pd.DataFrame(all_results)\n",
        "\n",
        "# Sort by RMSE (lower is better)\n",
        "results_df = results_df.sort_values('RMSE').reset_index(drop=True)\n",
        "\n",
        "print(\"\\nüèÜ FINAL MODEL COMPARISON:\")\n",
        "print(\"=\" * 60)\n",
        "print(results_df[['Model', 'RMSE', 'MAE', 'R¬≤', 'CV_Score']].round(4))\n",
        "\n",
        "# Identify best model\n",
        "best_model_name = results_df.iloc[0]['Model']\n",
        "best_rmse = results_df.iloc[0]['RMSE']\n",
        "best_r2 = results_df.iloc[0]['R¬≤']\n",
        "\n",
        "print(f\"\\nü•á BEST MODEL: {best_model_name}\")\n",
        "print(f\"   RMSE: {best_rmse:.4f}\")\n",
        "print(f\"   R¬≤: {best_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization: Model Comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# RMSE comparison\n",
        "axes[0, 0].bar(results_df['Model'], results_df['RMSE'], color='skyblue', alpha=0.7)\n",
        "axes[0, 0].set_title('RMSE Comparison (Lower is Better)', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('RMSE')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# R¬≤ comparison\n",
        "axes[0, 1].bar(results_df['Model'], results_df['R¬≤'], color='lightgreen', alpha=0.7)\n",
        "axes[0, 1].set_title('R¬≤ Comparison (Higher is Better)', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_ylabel('R¬≤')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# MAE comparison\n",
        "axes[1, 0].bar(results_df['Model'], results_df['MAE'], color='orange', alpha=0.7)\n",
        "axes[1, 0].set_title('MAE Comparison (Lower is Better)', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('MAE')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# CV Score comparison\n",
        "axes[1, 1].bar(results_df['Model'], results_df['CV_Score'], color='pink', alpha=0.7)\n",
        "axes[1, 1].set_title('Cross-Validation Score (Lower is Better)', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('CV Score (MSE)')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance Analysis (for tree-based models)\n",
        "if LIGHTGBM_AVAILABLE and 'lgb_search' in locals():\n",
        "    print(\"\\nüîç LightGBM Feature Importance (Top 20):\")\n",
        "    feature_importance = lgb_search.best_estimator_.feature_importances_\n",
        "    feature_names = X_train.columns\n",
        "    \n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': feature_importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(importance_df.head(20))\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    top_features = importance_df.head(20)\n",
        "    plt.barh(range(len(top_features)), top_features['importance'])\n",
        "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title('LightGBM Feature Importance (Top 20)', fontweight='bold')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if XGBOOST_AVAILABLE and 'xgb_search' in locals():\n",
        "    print(\"\\nüîç XGBoost Feature Importance (Top 20):\")\n",
        "    feature_importance = xgb_search.best_estimator_.feature_importances_\n",
        "    feature_names = X_train.columns\n",
        "    \n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': feature_importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(importance_df.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Residual Analysis for best model\n",
        "def plot_residuals(y_true, y_pred, model_name, ax):\n",
        "    residuals = y_true - y_pred\n",
        "    ax.scatter(y_pred, residuals, alpha=0.6)\n",
        "    ax.axhline(y=0, color='red', linestyle='--')\n",
        "    ax.set_xlabel('Predicted Values')\n",
        "    ax.set_ylabel('Residuals')\n",
        "    ax.set_title(f'{model_name} Residuals')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Get predictions for best model\n",
        "if best_model_name == 'Ridge':\n",
        "    best_predictions = ridge_pred\n",
        "elif best_model_name == 'Lasso':\n",
        "    best_predictions = lasso_pred\n",
        "elif best_model_name == 'ElasticNet':\n",
        "    best_predictions = elasticnet_pred\n",
        "elif best_model_name == 'LightGBM' and LIGHTGBM_AVAILABLE:\n",
        "    best_predictions = lgb_pred\n",
        "elif best_model_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
        "    best_predictions = xgb_pred\n",
        "\n",
        "# Plot residuals\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Residuals plot\n",
        "plot_residuals(y_test, best_predictions, best_model_name, axes[0])\n",
        "\n",
        "# Actual vs Predicted\n",
        "axes[1].scatter(y_test, best_predictions, alpha=0.6)\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[1].set_xlabel('Actual Values')\n",
        "axes[1].set_ylabel('Predicted Values')\n",
        "axes[1].set_title(f'{best_model_name} Actual vs Predicted')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results for production use\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Create models directory if it doesn't exist\n",
        "models_dir = Path('../models')\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save model comparison results\n",
        "results_df.to_csv(models_dir / 'model_comparison.csv', index=False)\n",
        "\n",
        "# Save best model hyperparameters\n",
        "best_model_info = results_df.iloc[0]\n",
        "hyperparams = {\n",
        "    'best_model': best_model_name,\n",
        "    'best_params': best_model_info['Best_Params'],\n",
        "    'performance': {\n",
        "        'RMSE': float(best_model_info['RMSE']),\n",
        "        'MAE': float(best_model_info['MAE']),\n",
        "        'R¬≤': float(best_model_info['R¬≤']),\n",
        "        'CV_Score': float(best_model_info['CV_Score'])\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(models_dir / 'best_model_config.json', 'w') as f:\n",
        "    json.dump(hyperparams, f, indent=2)\n",
        "\n",
        "print(f\"\\nüíæ Results saved to {models_dir}/\")\n",
        "print(f\"   - model_comparison.csv\")\n",
        "print(f\"   - best_model_config.json\")\n",
        "\n",
        "print(f\"\\nüéØ Next Steps:\")\n",
        "print(f\"   1. Best model identified: {best_model_name}\")\n",
        "print(f\"   2. Implement ModelTrainer class in src/Modeling.py\")\n",
        "print(f\"   3. Update app.py to integrate modeling pipeline\")\n",
        "print(f\"   4. Generate comprehensive ModelReport.md\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
