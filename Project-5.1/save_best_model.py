"""
Helper script to save the best model from existing model_comparison.csv
This is useful if you've already trained models but need to persist the best one.
"""

import pandas as pd
import json
import joblib
import ast
from pathlib import Path


def save_best_model_from_csv():
    """Load best model config from CSV and re-fit to save it"""

    models_dir = Path("models")
    csv_path = models_dir / "model_comparison.csv"

    if not csv_path.exists():
        print(f"âŒ {csv_path} not found. Please run model training first.")
        return False

    # Load comparison data
    print("ğŸ“Š Loading model comparison data...")
    results_df = pd.read_csv(csv_path)
    results_df = results_df.sort_values("RMSE")

    best_row = results_df.iloc[0]
    best_name = best_row["Model"]
    best_params_raw = best_row["Best_Params"]

    print(f"ğŸ¯ Best model: {best_name}")
    print(f"   RMSE: {best_row['RMSE']:.4f}")
    print(f"   RÂ²: {best_row['RÂ²']:.4f}")

    # Parse parameters
    if isinstance(best_params_raw, str):
        try:
            best_params = ast.literal_eval(best_params_raw)
        except:
            print(f"âš ï¸ Could not parse parameters: {best_params_raw}")
            return False
    else:
        best_params = best_params_raw

    # Load training data
    processed_dir = Path("data/processed")
    train_path = processed_dir / "train_encoded.csv"

    if not train_path.exists():
        print(f"âŒ Training data not found: {train_path}")
        print("   Please run the encoding step first.")
        return False

    print(f"\nğŸ“Š Loading training data from {train_path}...")
    train_df = pd.read_csv(train_path)
    X_train = train_df.drop("SalePrice", axis=1)
    y_train = train_df["SalePrice"]

    print(f"   Features: {X_train.shape[1]}, Samples: {X_train.shape[0]}")

    # Build model mapping
    model_mapping = {}

    # Linear models
    from sklearn.linear_model import Ridge, Lasso, ElasticNet, HuberRegressor

    model_mapping["Ridge"] = Ridge
    model_mapping["Lasso"] = Lasso
    model_mapping["ElasticNet"] = ElasticNet
    model_mapping["Huber"] = HuberRegressor

    # Tree-based models
    try:
        import lightgbm as lgb

        model_mapping["LightGBM"] = lgb.LGBMRegressor
    except ImportError:
        pass

    try:
        import xgboost as xgb

        model_mapping["XGBoost"] = xgb.XGBRegressor
    except ImportError:
        pass

    if best_name not in model_mapping:
        print(f"\nâŒ Model '{best_name}' is not supported.")
        print(f"   Supported models: {', '.join(model_mapping.keys())}")
        return False

    # Create and train model
    print(f"\nğŸ”§ Creating {best_name} model with best parameters...")
    BestModelClass = model_mapping[best_name]

    # Set default params
    if best_name in ["LightGBM", "XGBoost"]:
        default_params = {"random_state": 42, "verbosity": 0, "verbose": -1}
        if best_name == "LightGBM":
            default_params["verbose"] = -1
        elif best_name == "XGBoost":
            default_params["verbosity"] = 0
        best_params = {**default_params, **best_params}
    elif best_name in ["Ridge", "Lasso", "ElasticNet"]:
        if "random_state" not in best_params:
            best_params["random_state"] = 42

    print(f"   Parameters: {best_params}")

    model = BestModelClass(**best_params)
    print("   Training model...")
    model.fit(X_train, y_train)

    # Save model
    model_path = models_dir / "best_model.pkl"
    joblib.dump(model, model_path)
    print(f"   âœ“ Model saved to: {model_path}")

    # Save features
    features_path = models_dir / "best_model_features.json"
    with open(features_path, "w") as f:
        json.dump(list(X_train.columns), f, indent=2)
    print(f"   âœ“ Features saved to: {features_path}")

    print(f"\nâœ… Successfully saved best model ({best_name})!")
    return True


if __name__ == "__main__":
    save_best_model_from_csv()
